[
  {
    "objectID": "about.html#warnings-and-caveats",
    "href": "about.html#warnings-and-caveats",
    "title": "Predicting Survival of Intensive Care Unit Paitents with Support Vector Machines",
    "section": "Warnings and Caveats",
    "text": "Warnings and Caveats\nWe used easy packages to install packages. as part of this it will run the install from everything in pkgs.r. As such, running a render or a preview will attempt to install any packages without prompting you to agree to installing them. We have hardcoded the repo for cran in the package installer but if thats compremised the auto install could cause security concerns."
  },
  {
    "objectID": "about.html#rendering-the-page",
    "href": "about.html#rendering-the-page",
    "title": "Predicting Survival of Intensive Care Unit Paitents with Support Vector Machines",
    "section": "Rendering the page",
    "text": "Rendering the page\nFor best results, run quarto render --cache as this takes a long time to render the visualizations and build and tune the model.\nYou will need to install the following system libraries in order for the r code to work properly\n\nlibgit2\nlibharfbuzz-dev (debian, ubuntu, etc)\n\nharfbuzz-devel(fedora, EPEL)\n\nlibfribidi-dev (debian, ubuntu, etc)\n\nfribidi-devl (fedora, EPEL) libv8 or libnode-dev\n\n\nsudo apt-get install libcurl4-openssl-dev\nsudo apt-get install libcurl4-openssl-dev sudo apt-get install libcurl4-openssl-dev # Complete References ::: {#refs} :::"
  },
  {
    "objectID": "Journal/eric.html",
    "href": "Journal/eric.html",
    "title": "Eric’s Journal Entries",
    "section": "",
    "text": "https://www.jstatsoft.org/article/view/v015i09\nThe above article from the Journal of statistical Software outlines what Support Vector Machines are and what their use cases can be. The article continues by leveraging the mathematical equations for classification and regression as well as deployment strategies for data sets in R. The article concludes with examples of code and outputs showcasing the results on the iris data set.\n\n\n\nhttps://seis.bristol.ac.uk/~enicgc/pubs/1999/ijcai_ss.pdf\nThe above speaks to controlling the sensitivity of Support Vector Machines to reduce the number of False Positives/Negatives in the output. Veropoulos, Campbell, and Cristianini go on to detail the difference between Sensitivity and Specificity through various mathematical approaches and analyses. Their research with medical data sets where Box constraints were not statistically significant between the 4 data sets. However, the strain on the algorithm was insignificant and could aid in over all determinations."
  },
  {
    "objectID": "Journal/eric.html#support-vector-machines-in-r-karatzoglou2006",
    "href": "Journal/eric.html#support-vector-machines-in-r-karatzoglou2006",
    "title": "Eric’s Journal Entries",
    "section": "",
    "text": "https://www.jstatsoft.org/article/view/v015i09\nThe above article from the Journal of statistical Software outlines what Support Vector Machines are and what their use cases can be. The article continues by leveraging the mathematical equations for classification and regression as well as deployment strategies for data sets in R. The article concludes with examples of code and outputs showcasing the results on the iris data set."
  },
  {
    "objectID": "Journal/eric.html#controlling-the-sensitivity-of-support-vector-machines-cristianini2002",
    "href": "Journal/eric.html#controlling-the-sensitivity-of-support-vector-machines-cristianini2002",
    "title": "Eric’s Journal Entries",
    "section": "",
    "text": "https://seis.bristol.ac.uk/~enicgc/pubs/1999/ijcai_ss.pdf\nThe above speaks to controlling the sensitivity of Support Vector Machines to reduce the number of False Positives/Negatives in the output. Veropoulos, Campbell, and Cristianini go on to detail the difference between Sensitivity and Specificity through various mathematical approaches and analyses. Their research with medical data sets where Box constraints were not statistically significant between the 4 data sets. However, the strain on the algorithm was insignificant and could aid in over all determinations."
  },
  {
    "objectID": "Journal/eric.html#time-series-prediction-using-support-vector-machines-a-survey-sapankevych2009",
    "href": "Journal/eric.html#time-series-prediction-using-support-vector-machines-a-survey-sapankevych2009",
    "title": "Eric’s Journal Entries",
    "section": "Time Series Prediction Using Support Vector Machines: A Survey (Sapankevych and Sankar 2009)",
    "text": "Time Series Prediction Using Support Vector Machines: A Survey (Sapankevych and Sankar 2009)\nhttps://ieeexplore.ieee.org/abstract/document/4840324\nThis article details the ways in which Support Vector Machines have been utilized to perform time series analysis. I found this very interesting as in my current line of work we are looking for ways to implement more Machine Learning into our models and we do a fair amount of Time Series Analysis. This is a important topic for us as we start to work through the best way we can utilize and implement our model and how to best identify the uses for the model. Additionally this article delves into SVR and how that methodology can also be utilized in Time Series modeling."
  },
  {
    "objectID": "Journal/eric.html#a-comparative-analysis-of-k-nearest-neighbor-genetic-support-vector-machine-decision-tree-and-long-short-term-memory-algorithms-in-machine-learning-bansal2022",
    "href": "Journal/eric.html#a-comparative-analysis-of-k-nearest-neighbor-genetic-support-vector-machine-decision-tree-and-long-short-term-memory-algorithms-in-machine-learning-bansal2022",
    "title": "Eric’s Journal Entries",
    "section": "A comparative analysis of K-Nearest Neighbor, Genetic, Support Vector Machine, Decision Tree, and Long Short Term Memory algorithms in machine learning (Bansal, Goyal, and Choudhary 2022)",
    "text": "A comparative analysis of K-Nearest Neighbor, Genetic, Support Vector Machine, Decision Tree, and Long Short Term Memory algorithms in machine learning (Bansal, Goyal, and Choudhary 2022)\nhttps://www.sciencedirect.com/science/article/pii/S2772662222000261\nThe above article delves into the comparative difference between a few different methodologies relative to Machine Learning, such as KNN, SVM, and LSTM. The article further details the strengths and weaknesses of each and their most practical use cases based on what the implementer is ultimately seeking to achieve. Ultimately this provides more context on how to best utilize our model and to most effectively choose our groups data set so that when we start building our project we are not starting off on the wrong foot."
  },
  {
    "objectID": "Journal/eric.html#fast-training-support-vector-machines-using-parallel-sequential-minimal-optimization-zeng2008",
    "href": "Journal/eric.html#fast-training-support-vector-machines-using-parallel-sequential-minimal-optimization-zeng2008",
    "title": "Eric’s Journal Entries",
    "section": "Fast training Support Vector Machines using parallel sequential minimal optimization (Zeng et al. 2008)",
    "text": "Fast training Support Vector Machines using parallel sequential minimal optimization (Zeng et al. 2008)\nhttps://ieeexplore.ieee.org/abstract/document/4731075\nThe article above details out the various ways we can quickly train SVM models utilizing Sequential Minimal Optimization (SMO) algorithms to reduce the problems that can arise from large scale programming. A parallel SMO method was the primary focus of this paper as it covered the basic functions and algorithms behind the inner workings as applied to an SVM."
  },
  {
    "objectID": "Journal/eric.html#support-vector-machine-accuracy-improvement-with-classification-mohan2020",
    "href": "Journal/eric.html#support-vector-machine-accuracy-improvement-with-classification-mohan2020",
    "title": "Eric’s Journal Entries",
    "section": "Support Vector Machine Accuracy Improvement with Classification (Mohan et al. 2020)",
    "text": "Support Vector Machine Accuracy Improvement with Classification (Mohan et al. 2020)\nhttps://ieeexplore.ieee.org/abstract/document/9242572\nThis article walks through how to successfully setup and run an SVM based on a binary classification problem. Furthermore, it details the inner workings of various types of kernels that can be used to accurately map your planes based on the complexity of the data. I found this particularly interesting as I was wondering about what kernel to build upon and it seems as if an RBF or a Gaussian kernel might be our ticket."
  },
  {
    "objectID": "Journal/eric.html#effectiveness-of-random-search-in-svm-hyper-parameter-tuning-mantovani2015",
    "href": "Journal/eric.html#effectiveness-of-random-search-in-svm-hyper-parameter-tuning-mantovani2015",
    "title": "Eric’s Journal Entries",
    "section": "Effectiveness of Random Search in SVM hyper-parameter tuning (Mantovani et al. 2015)",
    "text": "Effectiveness of Random Search in SVM hyper-parameter tuning (Mantovani et al. 2015)\nhttps://ieeexplore.ieee.org/abstract/document/7280664\nThe authors of this article delve into the theory and techniques of tuning the Hyper-Parameters utilized by the SVM in relation classification, specifically Random Search. Often times this tuning requires a significant time investment with trial and error. It can also require specific knowledge of the data and outcomes associated with the training of the model, and frequently different variables will yield greater results dependent on the outcome. They concluded that given low dimensionality data sets Random Search can yield similar predictive results as more complex tuning methods such as grid search and meta-heuris tics."
  },
  {
    "objectID": "Journal/eric.html#empirical-evaluation-of-resampling-procedures-for-optimising-svm-hyperparameters",
    "href": "Journal/eric.html#empirical-evaluation-of-resampling-procedures-for-optimising-svm-hyperparameters",
    "title": "Eric’s Journal Entries",
    "section": "Empirical Evaluation of Resampling Procedures for Optimising SVM Hyperparameters",
    "text": "Empirical Evaluation of Resampling Procedures for Optimising SVM Hyperparameters\nhttps://www.jmlr.org/papers/volume18/16-174/16-174.pdf\nThe paper delves into the Radial Basis Function (RBF) Kernel of SVM’s and discusses the need for Hyper-Parameter selection between a regularization and a governing parameter. The paper goes on to detail that there is no generally accepted means for the optimization of Hyper-Parameters. Once approach is to continuously re-sample the initial training data from the data set utilizing different methods and then evaluate them. Ultimately the paper concludes that based on the research and testing of 17 varying methods of 121 data sets there is no definite solution to determine a one size fits all approach to selection of parameters based on an expected outcome."
  },
  {
    "objectID": "Journal/brad-08oct2023.html",
    "href": "Journal/brad-08oct2023.html",
    "title": "SVM application in Data Mining in EMR",
    "section": "",
    "text": "Support vector machines (SVMs) are a powerful method for machine learning that can be used for data mining. There are several different SVM kernels, and it is not always clear which one is best for a certain job. The goal of this paper is to help data scientists pick the best SVM kernel for a given job. The authors looked at how well different SVM models did at classification, regression, and clustering, among other data mining tasks. They used both real-world data and data that they made up themselves. The article by Xu et al. aimed to see how well various SVM kernels did at data mining jobs. They found that SVM with the RBF kernel did the best job at most data mining tasks. However, they also found that the performance of the different SVM kernels relies on the task and data set. One problem with this study is that there were only a few data mining jobs carried out. (5)\nMy next journal suggested a new SVM algorithm for jobs related to data mining. This is important since SVM is a powerful machine learning method, but they can be hard to train, especially on big datasets. The goal of this study is to suggest a new SVM algorithm that works better for data mining. They came up with a new SV algorithm that is made for data mining jobs. The program uses several methods to improve how well SVM training works. They tested how well their new SVM algorithm did at classification, regression, and grouping, among other tasks in data mining. They found that their new SVM algorithm was better at most data mining jobs than other SVM algorithms. But this algorithm has a weakness in that it is harder to understand than other SVM algorithms. (3)\nIn addition, Zhou et al wrote about deep mining of electronic medical data using support vector machines to predict the prognosis of severe, acute myocardial infarction. The authors talked about how the MIMIC-3 database is used to find the 13 markers for heart attack cases. They compared SVM algorithms and found that the model was about 92% accurate. They use this model to pull out certain features from the EMR and identify which patients will have a MI. They said that this helps doctors figure out the classification regression parts of a disease outlook. (6)\nMy next piece was about how Fouodo et al and others used support vector machines for survival analysis with R. They used the survivalSVM package to do three different kinds of survival analysis. They used both regression and ranking, which is a mix of the two. The next way to find the constraints was to use regression followed by Cox proportional hazard models. They stated that the SVM worked about as well as other methods on the datasets they used. So, this R package makes it quick and easy to find out how likely a patient is to live. (2)\nAnother article was called “Using Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records.” The goal of this work is to show how support vector machines (SVMs) in electronic medical records (EMRs) can be used to classify diabetes mellitus. This study looked at how well SVMs can classify diabetes because they have been good at diagnosing other diseases from electronic medical records (EMRs). The writers used EMRs from both people with and without diabetes to train an SVM model. During preparation, noise and outliers were first taken out of the EMRs. The SVM model was then trained with the help of guided learning. (1)\nThe next journal discussed a way to predict hospital readmissions using support vector machines. The goal of this study is to make a support vector machine (SVM) model that can predict a patient’s return to the hospital. The importance was that going back to the hospital is a deadly problem in health care, and it can be expensive for patients. A reliable predictor of hospital readmission could help hospitals find people who are at risk and give them treatment to keep them from going back to the hospital. A solution is that a collection of electronic medical records (EMRs) was used to train an SVM model. First, during preprocessing, abnormalities were taken out of the EMRs. The SVM model was then trained with the help of guided learning and separated the information into two groups. With the SVM model, this included readmitted patients who had to go back to the hospital. (4)\nSVM was used by Vieira et al. to divide data into two groups. The algorithm maps the raw data to a high-dimensional feature space, where a linear classification surface is made. The SVM method then tries to find the best hyperplane that separates the two types of data by the most. The margin is the distance between the hyperplane and the data points in each group that are closest to the hyperplane. The SVM algorithm also uses a kernel function to move the raw data into a space with more dimensions, where it is easier to separate. The kernel function is a piece of math that figures out how similar two data points are to each other. SVM also uses regularization to control the trade-off between making the margin as big as possible and making the classification mistake as small as possible. The SVM algorithm learns from a set of labeled data, where each data point has a label that tells what group it belongs to. Once the SVM algorithm has been taught, it can be used to put new data points that have not been labeled into one of the two groups. (7)\nYang et al. evaluated the performance a version of GAN called conditional medical GAN (C-med GAN) could determine who would die among ICU patients. The study used data from the Medical Information Mart for Intensive Care III (MIMIC-III) database and compared the success of the C-med GAN with some baseline models, such as the simplified acute physiology score II (SAPS II), the support vector machine (SVM), and the multilayer perceptron (MLP). The dataset was split into three sizes, and a 5-fold grid search cross-validation process was used to find the best hyperparameters and then the best model selection for the C-med GAN. Area under the precision-recall curve (PR-AUC), area under the receiver operating characteristic curve (ROC-AUC), and F1 score were used to measure the C-med GAN’s accuracy. The study came up with a helpful method to use SAPS II results to directly estimate how long a patient will live. The results of this study could be used in intensive care to make it easier to predict mortality in the ICU. (8)\nThe next article was about SVM and classifying cancer diagnosis using decision support. Chandrashekar et al compared SVM to KNN, RF, bayes and a decision tree to see which algorithm was better at classifying cancer in patients. They pulled from 20 cancer databased and tried to recognize the pattern from genetic variants.  They came up with a preliminary model after much data cleanup and feature selection with 5 out of the 88 possible features.  They improved the model with the use of 16 important features and divided up to two model groups.  The authors trained on 20 datasets with one and just 15 with the other but still have 5 dataset to test from. The F1 score was 0.17 for the SVM model and 0.11, 0.34 for recall.  So, overall SVM has about 88% accuracy, which was better than the other ML algorithms and best performance overall. (9)\nMandakini et al used SVM to predict Heart and Liver disease, but they added Swarm Optimization alongside it.  They took their data from the UCI machine learning repository and then looked at the accuracy, error and recall of the model.  The authors stated that the SVM was a better classifier for predicting liver disorders and cardiac arrythmias.  They first normalized the dataset then trained it and constructed a SVM mode, then added a data structure.  Later, they optimized the SVM model using the Crazy Particle Swarm Optimization (CPSO).  Then they added a Cauchy mutation and constructed their model.  Finally, they could test and classify their data with an F1 score of 89.55 for just SVM on heart disease and 77.24 on liver disease and 90% precision. They were able to increase that by 10-20 points on the F1 score by adding the CPSO on top of the SVM model. (10)\nReferences\n(1) Adeoye, Abiodun O., et al. Utilizing Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records. International Journal of Advanced Computer Science and Information Technology (IJACSIT), vol. 11, no. 10, 2021, pp. 102-114.\n(2) Fouodo, Cesaire, et al. Support Vector Machines for Survival Analysis with R. R Journal, vol. 14, no. 2, 2022, pp. 92-107.\n(3) Hu, Xiangfen, Wei Huang, and Qiang Wu. A New Support Vector Machine Algorithm for Data Mining.” Knowledge-Based Systems, vol. 112, 2016, pp. 118-128.\n(4) Ismail, Gaber A., et al. An Approach Using Support Vector Machines to Predict Hospital Readmission.” Journal of Medical Systems, vol. 44, no. 9, 2020, pp. 1-10.\n(5) Xu, Fei, Lihong Li, and Zhihua Zhou. SVM Kernels for Data Mining: A Comparative Study.” Proceedings of the 2010 SIAM International Conference on Data Mining (SDM), 2010, 585-596.\n(6) Zhou, Xingyu, et al. Using Support Vector Machines for Deep Mining of Electronic Medical Records in Order to Predict Prognosis of Severe, Acute Myocardial Infarction. Frontiers in Cardiovascular Medicine, vol. 10, 2023, p.918.\n(7) Vieira, S.M., Mendonça, L. F., Farinha, G. J., & Sousa, J. M. C. (2013). Modified binary PSO for feature selection using SVM applied to mortality prediction of septic patients. Applied Soft Computing, 13(8), 3494–3504. https://doi.org/10.1016/j.asoc.2013.03.021\n(8) Yang, Zou, H., Wang, M., Zhang, Q., Li, S., & Liang, H. (2023). Mortality prediction among ICU inpatients based on MIMIC-III database results from the conditional medical generative adversarial network. Heliyon, 9(2), e13200–e13200. https://doi.org/10.1016/j.heliyon.2023.e13200\n(9) Chandrashekar, K., Setlur, A. S., Sabhapathi C, A., Raiker, S. S., Singh, S., & Niranjan, V. (2023). Decision Support System and Web-Application Using Supervised Machine Learning Algorithms for Easy Cancer Classifications. Cancer informatics, 22, 11769351221147244. https://doi.org/10.1177/11769351221147244\n(10) Mandakini Priyadarshani Behera, Archana Sarangi, Debahuti Mishra, Shubhendu Kumar Sarangi, A Hybrid Machine Learning algorithm for Heart and Liver Disease Prediction Using Modified Particle Swarm Optimization with Support Vector Machine, Procedia Computer Science, Volume 218, 2023,Pages 818-827, https://doi.org/10.1016/j.procs.2023.01.062.\nIntroduction\nSupport Vector Machines (SVM) are an efficient way to mine data by serving as a classification algorithm in Electronic Medical Records (EMR). We find patterns in the data that might be hidden with other statistical methods. SVMs will be used to make models that can use new data to make accurate predictions. It is important to keep in mind, though, that SVMs can be hard to train, especially on big datasets. SVMs can also be responsive to how the SVM kernel and hyperparameters are chosen. Once the SVM model has been trained, it can be used to guess what will happen with new data. For example, a model could be used to figure out how likely it is that a patient will get a certain illness or what will happen to a patient who already has that disease. Before using SVMs for data mining in EMRs, we need to prepare the data since the noise and outliers should be taken out of the data. It is also important to feature engineer the data, which will help make new features that may be more useful for the SVM model.\nSVMs can be used to get useful information from the data and to make models that can improve the care of patients. SVMs can determine a model to predict which patients might survive a severe illness in the hospital. This is important for data mining in EMRs, where the data is often complicated since SVMs can handle noise and errors well. This is important for data mining in EMRs because the data may have errors or missing data. This is important for data mining in EMRs because it would be helpful to know how the models work, so we can have evidence to support the results. Overall, SVMs can mine data in EMRs to create a new SVM that can improve the care of patients by modeling who is at increased risk of death. This can assist in predicting the probability of those patients at risk for mortality in the Intensive Care Unit (ICU)."
  },
  {
    "objectID": "Journal/brad-08oct2023.html#summary-of-articles",
    "href": "Journal/brad-08oct2023.html#summary-of-articles",
    "title": "SVM application in Data Mining in EMR",
    "section": "",
    "text": "Support vector machines (SVMs) are a powerful method for machine learning that can be used for data mining. There are several different SVM kernels, and it is not always clear which one is best for a certain job. The goal of this paper is to help data scientists pick the best SVM kernel for a given job. The authors looked at how well different SVM models did at classification, regression, and clustering, among other data mining tasks. They used both real-world data and data that they made up themselves. The article by Xu et al. aimed to see how well various SVM kernels did at data mining jobs. They found that SVM with the RBF kernel did the best job at most data mining tasks. However, they also found that the performance of the different SVM kernels relies on the task and data set. One problem with this study is that there were only a few data mining jobs carried out. (5)\nMy next journal suggested a new SVM algorithm for jobs related to data mining. This is important since SVM is a powerful machine learning method, but they can be hard to train, especially on big datasets. The goal of this study is to suggest a new SVM algorithm that works better for data mining. They came up with a new SV algorithm that is made for data mining jobs. The program uses several methods to improve how well SVM training works. They tested how well their new SVM algorithm did at classification, regression, and grouping, among other tasks in data mining. They found that their new SVM algorithm was better at most data mining jobs than other SVM algorithms. But this algorithm has a weakness in that it is harder to understand than other SVM algorithms. (3)\nIn addition, Zhou et al wrote about deep mining of electronic medical data using support vector machines to predict the prognosis of severe, acute myocardial infarction. The authors talked about how the MIMIC-3 database is used to find the 13 markers for heart attack cases. They compared SVM algorithms and found that the model was about 92% accurate. They use this model to pull out certain features from the EMR and identify which patients will have a MI. They said that this helps doctors figure out the classification regression parts of a disease outlook. (6)\nMy next piece was about how Fouodo et al and others used support vector machines for survival analysis with R. They used the survivalSVM package to do three different kinds of survival analysis. They used both regression and ranking, which is a mix of the two. The next way to find the constraints was to use regression followed by Cox proportional hazard models. They stated that the SVM worked about as well as other methods on the datasets they used. So, this R package makes it quick and easy to find out how likely a patient is to live. (2)\nAnother article was called “Using Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records.” The goal of this work is to show how support vector machines (SVMs) in electronic medical records (EMRs) can be used to classify diabetes mellitus. This study looked at how well SVMs can classify diabetes because they have been good at diagnosing other diseases from electronic medical records (EMRs). The writers used EMRs from both people with and without diabetes to train an SVM model. During preparation, noise and outliers were first taken out of the EMRs. The SVM model was then trained with the help of guided learning. (1)\nThe next journal discussed a way to predict hospital readmissions using support vector machines. The goal of this study is to make a support vector machine (SVM) model that can predict a patient’s return to the hospital. The importance was that going back to the hospital is a deadly problem in health care, and it can be expensive for patients. A reliable predictor of hospital readmission could help hospitals find people who are at risk and give them treatment to keep them from going back to the hospital. A solution is that a collection of electronic medical records (EMRs) was used to train an SVM model. First, during preprocessing, abnormalities were taken out of the EMRs. The SVM model was then trained with the help of guided learning and separated the information into two groups. With the SVM model, this included readmitted patients who had to go back to the hospital. (4)\nSVM was used by Vieira et al. to divide data into two groups. The algorithm maps the raw data to a high-dimensional feature space, where a linear classification surface is made. The SVM method then tries to find the best hyperplane that separates the two types of data by the most. The margin is the distance between the hyperplane and the data points in each group that are closest to the hyperplane. The SVM algorithm also uses a kernel function to move the raw data into a space with more dimensions, where it is easier to separate. The kernel function is a piece of math that figures out how similar two data points are to each other. SVM also uses regularization to control the trade-off between making the margin as big as possible and making the classification mistake as small as possible. The SVM algorithm learns from a set of labeled data, where each data point has a label that tells what group it belongs to. Once the SVM algorithm has been taught, it can be used to put new data points that have not been labeled into one of the two groups. (7)\nYang et al. evaluated the performance a version of GAN called conditional medical GAN (C-med GAN) could determine who would die among ICU patients. The study used data from the Medical Information Mart for Intensive Care III (MIMIC-III) database and compared the success of the C-med GAN with some baseline models, such as the simplified acute physiology score II (SAPS II), the support vector machine (SVM), and the multilayer perceptron (MLP). The dataset was split into three sizes, and a 5-fold grid search cross-validation process was used to find the best hyperparameters and then the best model selection for the C-med GAN. Area under the precision-recall curve (PR-AUC), area under the receiver operating characteristic curve (ROC-AUC), and F1 score were used to measure the C-med GAN’s accuracy. The study came up with a helpful method to use SAPS II results to directly estimate how long a patient will live. The results of this study could be used in intensive care to make it easier to predict mortality in the ICU. (8)\nThe next article was about SVM and classifying cancer diagnosis using decision support. Chandrashekar et al compared SVM to KNN, RF, bayes and a decision tree to see which algorithm was better at classifying cancer in patients. They pulled from 20 cancer databased and tried to recognize the pattern from genetic variants.  They came up with a preliminary model after much data cleanup and feature selection with 5 out of the 88 possible features.  They improved the model with the use of 16 important features and divided up to two model groups.  The authors trained on 20 datasets with one and just 15 with the other but still have 5 dataset to test from. The F1 score was 0.17 for the SVM model and 0.11, 0.34 for recall.  So, overall SVM has about 88% accuracy, which was better than the other ML algorithms and best performance overall. (9)\nMandakini et al used SVM to predict Heart and Liver disease, but they added Swarm Optimization alongside it.  They took their data from the UCI machine learning repository and then looked at the accuracy, error and recall of the model.  The authors stated that the SVM was a better classifier for predicting liver disorders and cardiac arrythmias.  They first normalized the dataset then trained it and constructed a SVM mode, then added a data structure.  Later, they optimized the SVM model using the Crazy Particle Swarm Optimization (CPSO).  Then they added a Cauchy mutation and constructed their model.  Finally, they could test and classify their data with an F1 score of 89.55 for just SVM on heart disease and 77.24 on liver disease and 90% precision. They were able to increase that by 10-20 points on the F1 score by adding the CPSO on top of the SVM model. (10)\nReferences\n(1) Adeoye, Abiodun O., et al. Utilizing Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records. International Journal of Advanced Computer Science and Information Technology (IJACSIT), vol. 11, no. 10, 2021, pp. 102-114.\n(2) Fouodo, Cesaire, et al. Support Vector Machines for Survival Analysis with R. R Journal, vol. 14, no. 2, 2022, pp. 92-107.\n(3) Hu, Xiangfen, Wei Huang, and Qiang Wu. A New Support Vector Machine Algorithm for Data Mining.” Knowledge-Based Systems, vol. 112, 2016, pp. 118-128.\n(4) Ismail, Gaber A., et al. An Approach Using Support Vector Machines to Predict Hospital Readmission.” Journal of Medical Systems, vol. 44, no. 9, 2020, pp. 1-10.\n(5) Xu, Fei, Lihong Li, and Zhihua Zhou. SVM Kernels for Data Mining: A Comparative Study.” Proceedings of the 2010 SIAM International Conference on Data Mining (SDM), 2010, 585-596.\n(6) Zhou, Xingyu, et al. Using Support Vector Machines for Deep Mining of Electronic Medical Records in Order to Predict Prognosis of Severe, Acute Myocardial Infarction. Frontiers in Cardiovascular Medicine, vol. 10, 2023, p.918.\n(7) Vieira, S.M., Mendonça, L. F., Farinha, G. J., & Sousa, J. M. C. (2013). Modified binary PSO for feature selection using SVM applied to mortality prediction of septic patients. Applied Soft Computing, 13(8), 3494–3504. https://doi.org/10.1016/j.asoc.2013.03.021\n(8) Yang, Zou, H., Wang, M., Zhang, Q., Li, S., & Liang, H. (2023). Mortality prediction among ICU inpatients based on MIMIC-III database results from the conditional medical generative adversarial network. Heliyon, 9(2), e13200–e13200. https://doi.org/10.1016/j.heliyon.2023.e13200\n(9) Chandrashekar, K., Setlur, A. S., Sabhapathi C, A., Raiker, S. S., Singh, S., & Niranjan, V. (2023). Decision Support System and Web-Application Using Supervised Machine Learning Algorithms for Easy Cancer Classifications. Cancer informatics, 22, 11769351221147244. https://doi.org/10.1177/11769351221147244\n(10) Mandakini Priyadarshani Behera, Archana Sarangi, Debahuti Mishra, Shubhendu Kumar Sarangi, A Hybrid Machine Learning algorithm for Heart and Liver Disease Prediction Using Modified Particle Swarm Optimization with Support Vector Machine, Procedia Computer Science, Volume 218, 2023,Pages 818-827, https://doi.org/10.1016/j.procs.2023.01.062.\nIntroduction\nSupport Vector Machines (SVM) are an efficient way to mine data by serving as a classification algorithm in Electronic Medical Records (EMR). We find patterns in the data that might be hidden with other statistical methods. SVMs will be used to make models that can use new data to make accurate predictions. It is important to keep in mind, though, that SVMs can be hard to train, especially on big datasets. SVMs can also be responsive to how the SVM kernel and hyperparameters are chosen. Once the SVM model has been trained, it can be used to guess what will happen with new data. For example, a model could be used to figure out how likely it is that a patient will get a certain illness or what will happen to a patient who already has that disease. Before using SVMs for data mining in EMRs, we need to prepare the data since the noise and outliers should be taken out of the data. It is also important to feature engineer the data, which will help make new features that may be more useful for the SVM model.\nSVMs can be used to get useful information from the data and to make models that can improve the care of patients. SVMs can determine a model to predict which patients might survive a severe illness in the hospital. This is important for data mining in EMRs, where the data is often complicated since SVMs can handle noise and errors well. This is important for data mining in EMRs because the data may have errors or missing data. This is important for data mining in EMRs because it would be helpful to know how the models work, so we can have evidence to support the results. Overall, SVMs can mine data in EMRs to create a new SVM that can improve the care of patients by modeling who is at increased risk of death. This can assist in predicting the probability of those patients at risk for mortality in the Intensive Care Unit (ICU)."
  },
  {
    "objectID": "Journal/brad-08oct2023.html#methods",
    "href": "Journal/brad-08oct2023.html#methods",
    "title": "SVM application in Data Mining in EMR",
    "section": "Methods",
    "text": "Methods\nMIMIC-III is a , free database with information about the health of more than 40,000 people who stayed in the critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. The information has been stripped of all personal information. The database has information like demographics, measurements of vital signs taken at the bedside (about one data point per hour), lab test results, procedures, medicines, caregiver notes, imaging reports, and deaths (including those that happened after the patient was released from the hospital).\nMIMIC helps with a wide range of analytical studies, including statistics, improving clinical decision rules, and making electronic tools. It is important for three reasons: researchers from anywhere in the world can use it for free, it includes a very large and diverse group of ICU patients, and it has very detailed information like vital signs, lab results, and medications.\nUnder a data use agreement, MIMIC-III combines de-identified, complete clinical data from patients who were admitted to the Beth Israel Deaconess Medical Center in Boston, Massachusetts. This data is then made available to researchers all over the world. Because the data are public, clinical studies can be repeated and made better in ways that would not be possible otherwise.\nThe MIMIC-III database was filled with information that was collected during normal hospital care, so it didn’t add any extra work for nurses or get in the way of their work. Data was taken from a number of places, including:\nCritical care information tools and hospital electronic health record databases have records from the past.\nDeath by the Social Security Administration The main file.\nDuring the time when the data was collected, there were two different critical care information systems: the Philips CareVue Clinical Information System (types M2331A and M1215A; Philips Health-care, Andover, MA) and the iMDsoft MetaVision ICU (iMDsoft, Needham, MA).\nThese tools were where clinical information like:\nPhysiological measures taken by a nurse and time-stamped (for example, recording the heart rate, arterial blood pressure, or breathing rate every hour); care providers’ written notes on the patient’s progress; and medications and fluid balances given through an intravenous drip.\nWith the exception of data about fluid intake, which was very different between the CareVue and MetaVision systems in how it was set up, data was combined when the database tables were made. For data that couldn’t be combined, a suffix is added to show where the data came from. For example, inputs for patients being monitored with the CareVue system are stored in INPUTEVENTS_CV, while inputs for patients being monitored with the Metavision system are stored in INPUTEVENTS_MV. From hospital and lab health record systems, more information was gathered, including:\npatient characteristics and deaths in the hospital.\nSome examples of lab test results are hematology, chemistry, and microbiology.\ndischarge summaries and reports of imaging tests and electrocardiograms.\nInformation about bills, such as International Classification of Diseases, 9th Edition (ICD-9) codes, Diagnosis Related Group (DRG) codes, and Current Procedural Terminology (CPT) codes.\nThe Social Security Administration’s Death Master File was used to find out when people died outside of hospitals.\nBefore the data was put into the MIMIC-III database, it was deidentified using structured data cleaning and date shifting, as required by the Health Insurance Portability and Accountability Act (HIPAA). For structured data to be deidentified, all 18 of the identifying data elements listed in HIPAA had to be taken out. This included areas like the patient’s name, phone number, address, and dates. In particular, times were moved into the future by a random amount for each patient in the same way so that intervals could be kept. This made stays happen between the years 2100 and 2200. Date moving did not change the time of day, the day of the week, or the season. To hide their real ages and follow HIPAA rules, the dates of birth of patients older than 89 were changed. In the database, these patients have ages of over 300 years.\nProtected health information was taken out of free-text fields like diagnostic reports and doctor’s notes using a thoroughly tested deidentification system based on extensive dictionary look-ups and pattern-matching with regular expressions. As more information is collected, this deidentification device keeps getting more parts.\nInstitutional Review Boards at the Beth Israel Deaconess Medical Center in Boston, Massachusetts, and the Massachusetts Institute of Technology in Cambridge, Massachusetts, gave their approval to the project. Patients didn’t have to give their consent because the project didn’t affect professional care and all protected health information was made anonymous.\nMIMIC-III is a set of 26 tables that make up a relational database. Identifiers, which usually end in ‘ID’, are used to link tables together. For example, SUBJECT_ID is used to identify a unique patient, HADM_ID is used to identify a unique hospital admission, and ICUSTAY_ID is used to identify a unique hospital entry to an intensive care unit.\nIn a set of “events” tables, things like notes, lab tests, and fluid balance are kept track of. For example, the OUTPUTEVENTS table has all the information about a patient’s output, while the LABEVENTS table has the results of a patient’s lab tests.\nDictionary tables are those that start with “D_” and give meanings for identifiers. For example, each row of CHARTEVENTS has a single ITEMID that stands for the idea being measured, but it doesn’t have the name of the measurement. By joining CHARTEVENTS and D_ITEMS on ITEMID, you can find out what idea an ITEMID stands for.\nWhen making the MIMIC data model, it was important to find a balance between how easy it was to understand and how close it was to the real world. So, the model is a reflection of the data sources it is based on. The MIMIC database has been changed over time based on user comments. When changes were done, care was taken not to make assumptions about the underlying data. This means that MIMIC-III is a good representation of the raw hospital data.\nFive tables, called ADMISSIONS, PATIENTS, ICUSTAYS, SERVICES, and TRANSFERS, are used to describe and keep track of patient stays. Five more tables, D_CPT, D_ICD_DIAGNOSES, D_ICD_PROCEDURES, D_ITEMS, and D_LABITEMS, are dictionaries that let you look up codes by their meanings. The rest of the tables have information about patient care, like measurements of the patient’s body, notes from caregivers, and payment information.\nMIMIC-III is given as a set of comma-separated value (CSV) files and tools to help import the data into database systems like PostreSQL, MySQL, and MonetDB. Since the database has a lot of knowledge about how to care for patients clinically, it needs to be treated with care and respect.\nhttps://mimic.mit.edu/docs/iv/modules/icu/ is where we got the ICU dataset,\n Patient demographics:\no Age: Median 65.8 years (Q1–Q3: 52.8–77.8 years)\no Sex: 55.9% male\no In-hospital mortality: 11.5%\n Vital signs:\no Heart rate: Median 98 beats per minute (Q1–Q3: 76–120 beats per\nminute)\no Blood pressure: Median systolic blood pressure 134 mmHg (Q1–Q3:\n116–154 mmHg); median diastolic blood pressure 78 mmHg (Q1–Q3:\n66–90 mmHg)\no Respiratory rate: Median 20 breaths per minute (Q1–Q3: 16–24 breaths\nper minute)\no Temperature: Median 36.8 °C (Q1–Q3: 36.5–37.1 °C)\no Oxygen saturation: Median 96% (Q1–Q3: 93–99%)\n Laboratory values:\no White blood cell count: Median 10.5 × 10^9 cells/L (Q1–Q3: 7.5–14.5 ×\n10^9 cells/L)\no Neutrophil count: Median 7.5 × 10^9 cells/L (Q1–Q3: 5.4–11.2 × 10^9\ncells/L)\no Lymphocyte count: Median 1.7 × 10^9 cells/L (Q1–Q3: 1.0–2.5 × 10^9\ncells/L)\no Platelet count: Median 178 × 10^9 cells/L (Q1–Q3: 125–240 × 10^9\ncells/L)\no Creatinine: Median 1.0 mg/dL (Q1–Q3: 0.8–1.3 mg/dL)\no Bilirubin: Median 0.8 mg/dL (Q1–Q3: 0.5–1.2 mg/dL)\no Lactate dehydrogenase: Median 250 U/L (Q1–Q3: 190–330 U/L)"
  },
  {
    "objectID": "Journal/brad-08oct2023.html#analysis-and-results",
    "href": "Journal/brad-08oct2023.html#analysis-and-results",
    "title": "SVM application in Data Mining in EMR",
    "section": "Analysis and Results",
    "text": "Analysis and Results\n\nData and Visualization\n\n\n\n\nStatistical Modeling\n\n\nConclusion"
  },
  {
    "objectID": "Journal/brad-08oct2023.html#references",
    "href": "Journal/brad-08oct2023.html#references",
    "title": "SVM application in Data Mining in EMR",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "Journal/brad.html",
    "href": "Journal/brad.html",
    "title": "SVM application in Data Mining in EMR",
    "section": "",
    "text": "Support vector machines (SVMs) are a powerful method for machine learning that can be used for data mining. There are several different SVM kernels, and it is not always clear which one is best for a certain job. The goal of this paper is to help data scientists pick the best SVM kernel for a given job. The authors looked at how well different SVM models did at classification, regression, and clustering, among other data mining tasks. They used both real-world data and data that they made up themselves. The article by Xu et al. aimed to see how well various SVM kernels did at data mining jobs. They found that SVM with the RBF kernel did the best job at most data mining tasks. However, they also found that the performance of the different SVM kernels relies on the task and data set. One problem with this study is that there were only a few data mining jobs carried out. (5)\nMy next journal suggested a new SVM algorithm for jobs related to data mining. This is important since SVM is a powerful machine learning method, but they can be hard to train, especially on big datasets. The goal of this study is to suggest a new SVM algorithm that works better for data mining. They came up with a new SV algorithm that is made for data mining jobs. The program uses several methods to improve how well SVM training works. They tested how well their new SVM algorithm did at classification, regression, and grouping, among other tasks in data mining. They found that their new SVM algorithm was better at most data mining jobs than other SVM algorithms. But this algorithm has a weakness in that it is harder to understand than other SVM algorithms. (3)\nIn addition, Zhou et al wrote about deep mining of electronic medical data using support vector machines to predict the prognosis of severe, acute myocardial infarction. The authors talked about how the MIMIC-3 database is used to find the 13 markers for heart attack cases. They compared SVM algorithms and found that the model was about 92% accurate. They use this model to pull out certain features from the EMR and identify which patients will have a MI. They said that this helps doctors figure out the classification regression parts of a disease outlook. (6)\nMy next piece was about how Fouodo et al and others used support vector machines for survival analysis with R. They used the survivalSVM package to do three different kinds of survival analysis. They used both regression and ranking, which is a mix of the two. The next way to find the constraints was to use regression followed by Cox proportional hazard models. They stated that the SVM worked about as well as other methods on the datasets they used. So, this R package makes it quick and easy to find out how likely a patient is to live. (2)\nAnother article was called “Using Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records.” The goal of this work is to show how support vector machines (SVMs) in electronic medical records (EMRs) can be used to classify diabetes mellitus. This study looked at how well SVMs can classify diabetes because they have been good at diagnosing other diseases from electronic medical records (EMRs). The writers used EMRs from both people with and without diabetes to train an SVM model. During preparation, noise and outliers were first taken out of the EMRs. The SVM model was then trained with the help of guided learning. (1)\nThe next journal discussed a way to predict hospital readmissions using support vector machines. The goal of this study is to make a support vector machine (SVM) model that can predict a patient's return to the hospital. The importance was that going back to the hospital is a deadly problem in health care, and it can be expensive for patients. A reliable predictor of hospital readmission could help hospitals find people who are at risk and give them treatment to keep them from going back to the hospital. A solution is that a collection of electronic medical records (EMRs) was used to train an SVM model. First, during preprocessing, abnormalities were taken out of the EMRs. The SVM model was then trained with the help of guided learning and separated the information into two groups. With the SVM model, this included readmitted patients who had to go back to the hospital. (4)\nSVM was used by Vieira et al. to divide data into two groups. The algorithm maps the raw data to a high-dimensional feature space, where a linear classification surface is made. The SVM method then tries to find the best hyperplane that separates the two types of data by the most. The margin is the distance between the hyperplane and the data points in each group that are closest to the hyperplane. The SVM algorithm also uses a kernel function to move the raw data into a space with more dimensions, where it is easier to separate. The kernel function is a piece of math that figures out how similar two data points are to each other. SVM also uses regularization to control the trade-off between making the margin as big as possible and making the classification mistake as small as possible. The SVM algorithm learns from a set of labeled data, where each data point has a label that tells what group it belongs to. Once the SVM algorithm has been taught, it can be used to put new data points that have not been labeled into one of the two groups. (7)\nYang et al. evaluated the performance a version of GAN called conditional medical GAN (C-med GAN) could determine who would die among ICU patients. The study used data from the Medical Information Mart for Intensive Care III (MIMIC-III) database and compared the success of the C-med GAN with some baseline models, such as the simplified acute physiology score II (SAPS II), the support vector machine (SVM), and the multilayer perceptron (MLP). The dataset was split into three sizes, and a 5-fold grid search cross-validation process was used to find the best hyperparameters and then the best model selection for the C-med GAN. Area under the precision-recall curve (PR-AUC), area under the receiver operating characteristic curve (ROC-AUC), and F1 score were used to measure the C-med GAN’s accuracy. The study came up with a helpful method to use SAPS II results to directly estimate how long a patient will live. The results of this study could be used in intensive care to make it easier to predict mortality in the ICU. (8)\nReferences\n(1) Adeoye, Abiodun O., et al. Utilizing Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records. International Journal of Advanced Computer Science and Information Technology (IJACSIT), vol. 11, no. 10, 2021, pp. 102-114.\n(2) Fouodo, Cesaire, et al. Support Vector Machines for Survival Analysis with R. R Journal, vol. 14, no. 2, 2022, pp. 92-107.\n(3) Hu, Xiangfen, Wei Huang, and Qiang Wu. A New Support Vector Machine Algorithm for Data Mining.\" Knowledge-Based Systems, vol. 112, 2016, pp. 118-128.\n(4) Ismail, Gaber A., et al. An Approach Using Support Vector Machines to Predict Hospital Readmission.\" Journal of Medical Systems, vol. 44, no. 9, 2020, pp. 1-10.\n(5) Xu, Fei, Lihong Li, and Zhihua Zhou. SVM Kernels for Data Mining: A Comparative Study.\" Proceedings of the 2010 SIAM International Conference on Data Mining (SDM), 2010, 585-596.\n(6) Zhou, Xingyu, et al. Using Support Vector Machines for Deep Mining of Electronic Medical Records in Order to Predict Prognosis of Severe, Acute Myocardial Infarction. Frontiers in Cardiovascular Medicine, vol. 10, 2023, p.918.\n(7) Vieira, S.M., Mendonça, L. F., Farinha, G. J., & Sousa, J. M. C. (2013). Modified binary PSO for feature selection using SVM applied to mortality prediction of septic patients. Applied Soft Computing, 13(8), 3494–3504. https://doi.org/10.1016/j.asoc.2013.03.021\n(8) Yang, Zou, H., Wang, M., Zhang, Q., Li, S., & Liang, H. (2023). Mortality prediction among ICU inpatients based on MIMIC-III database results from the conditional medical generative adversarial network. Heliyon, 9(2), e13200–e13200. https://doi.org/10.1016/j.heliyon.2023.e13200\nIntroduction\nSupport Vector Machines (SVM) are a great way to mine data in Electronic Medical Records (EMR). You can use them to find patterns in the data that might be hard to find with regular statistical methods. SVMs can also be used to make models that can use new data to make accurate predictions. It is important to keep in mind, though, that SVMs can be hard to train, especially on big datasets. SVMs can also be responsive to how the SVM kernel and hyperparameters are chosen. Once the SVM model has been trained, it can be used to guess what will happen with new data. For example, a model could be used to figure out how likely it is that a patient will get a certain illness or what will happen to a patient who already has that disease. Before you can use SVMs for data mining in EMRs, you need to prepare the data since the noise and outliers should be taken out of the data. It is also important to feature engineer the data, which will help make new features that may be more useful for the SVM model.\nSVMs can be used to get useful information from the data and to make models that can improve the care of patients. Here are some more reasons why using SVMs for data mining in EMRs is helpful in the clinical setting.  SVMs can determine a model to predict which patients might survive a severe illness in the hospital. This is important for data mining in EMRs, where the data is often complicated since SVMs can handle noise and errors well. This is important for data mining in EMRs because the data may have errors or missing data. Also, models that are easy to understand can be made with SVMs which is important to medical providers so they can explain it to patients and their family.  This is important for data mining in EMRs because it would be helpful to know how the models work, so we can have evidence to support the results. Overall, SVMs are very helpful tools for mining data in EMRs since you get useful information from the data to make models that can improve the care of patients. This can assist in predicting those patients at risk for mortality or death in the Intensive Care Unit (ICU) which are the sickest of the patients."
  },
  {
    "objectID": "Journal/brad.html#summary-of-articles",
    "href": "Journal/brad.html#summary-of-articles",
    "title": "SVM application in Data Mining in EMR",
    "section": "",
    "text": "Support vector machines (SVMs) are a powerful method for machine learning that can be used for data mining. There are several different SVM kernels, and it is not always clear which one is best for a certain job. The goal of this paper is to help data scientists pick the best SVM kernel for a given job. The authors looked at how well different SVM models did at classification, regression, and clustering, among other data mining tasks. They used both real-world data and data that they made up themselves. The article by Xu et al. aimed to see how well various SVM kernels did at data mining jobs. They found that SVM with the RBF kernel did the best job at most data mining tasks. However, they also found that the performance of the different SVM kernels relies on the task and data set. One problem with this study is that there were only a few data mining jobs carried out. (5)\nMy next journal suggested a new SVM algorithm for jobs related to data mining. This is important since SVM is a powerful machine learning method, but they can be hard to train, especially on big datasets. The goal of this study is to suggest a new SVM algorithm that works better for data mining. They came up with a new SV algorithm that is made for data mining jobs. The program uses several methods to improve how well SVM training works. They tested how well their new SVM algorithm did at classification, regression, and grouping, among other tasks in data mining. They found that their new SVM algorithm was better at most data mining jobs than other SVM algorithms. But this algorithm has a weakness in that it is harder to understand than other SVM algorithms. (3)\nIn addition, Zhou et al wrote about deep mining of electronic medical data using support vector machines to predict the prognosis of severe, acute myocardial infarction. The authors talked about how the MIMIC-3 database is used to find the 13 markers for heart attack cases. They compared SVM algorithms and found that the model was about 92% accurate. They use this model to pull out certain features from the EMR and identify which patients will have a MI. They said that this helps doctors figure out the classification regression parts of a disease outlook. (6)\nMy next piece was about how Fouodo et al and others used support vector machines for survival analysis with R. They used the survivalSVM package to do three different kinds of survival analysis. They used both regression and ranking, which is a mix of the two. The next way to find the constraints was to use regression followed by Cox proportional hazard models. They stated that the SVM worked about as well as other methods on the datasets they used. So, this R package makes it quick and easy to find out how likely a patient is to live. (2)\nAnother article was called “Using Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records.” The goal of this work is to show how support vector machines (SVMs) in electronic medical records (EMRs) can be used to classify diabetes mellitus. This study looked at how well SVMs can classify diabetes because they have been good at diagnosing other diseases from electronic medical records (EMRs). The writers used EMRs from both people with and without diabetes to train an SVM model. During preparation, noise and outliers were first taken out of the EMRs. The SVM model was then trained with the help of guided learning. (1)\nThe next journal discussed a way to predict hospital readmissions using support vector machines. The goal of this study is to make a support vector machine (SVM) model that can predict a patient's return to the hospital. The importance was that going back to the hospital is a deadly problem in health care, and it can be expensive for patients. A reliable predictor of hospital readmission could help hospitals find people who are at risk and give them treatment to keep them from going back to the hospital. A solution is that a collection of electronic medical records (EMRs) was used to train an SVM model. First, during preprocessing, abnormalities were taken out of the EMRs. The SVM model was then trained with the help of guided learning and separated the information into two groups. With the SVM model, this included readmitted patients who had to go back to the hospital. (4)\nSVM was used by Vieira et al. to divide data into two groups. The algorithm maps the raw data to a high-dimensional feature space, where a linear classification surface is made. The SVM method then tries to find the best hyperplane that separates the two types of data by the most. The margin is the distance between the hyperplane and the data points in each group that are closest to the hyperplane. The SVM algorithm also uses a kernel function to move the raw data into a space with more dimensions, where it is easier to separate. The kernel function is a piece of math that figures out how similar two data points are to each other. SVM also uses regularization to control the trade-off between making the margin as big as possible and making the classification mistake as small as possible. The SVM algorithm learns from a set of labeled data, where each data point has a label that tells what group it belongs to. Once the SVM algorithm has been taught, it can be used to put new data points that have not been labeled into one of the two groups. (7)\nYang et al. evaluated the performance a version of GAN called conditional medical GAN (C-med GAN) could determine who would die among ICU patients. The study used data from the Medical Information Mart for Intensive Care III (MIMIC-III) database and compared the success of the C-med GAN with some baseline models, such as the simplified acute physiology score II (SAPS II), the support vector machine (SVM), and the multilayer perceptron (MLP). The dataset was split into three sizes, and a 5-fold grid search cross-validation process was used to find the best hyperparameters and then the best model selection for the C-med GAN. Area under the precision-recall curve (PR-AUC), area under the receiver operating characteristic curve (ROC-AUC), and F1 score were used to measure the C-med GAN’s accuracy. The study came up with a helpful method to use SAPS II results to directly estimate how long a patient will live. The results of this study could be used in intensive care to make it easier to predict mortality in the ICU. (8)\nReferences\n(1) Adeoye, Abiodun O., et al. Utilizing Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records. International Journal of Advanced Computer Science and Information Technology (IJACSIT), vol. 11, no. 10, 2021, pp. 102-114.\n(2) Fouodo, Cesaire, et al. Support Vector Machines for Survival Analysis with R. R Journal, vol. 14, no. 2, 2022, pp. 92-107.\n(3) Hu, Xiangfen, Wei Huang, and Qiang Wu. A New Support Vector Machine Algorithm for Data Mining.\" Knowledge-Based Systems, vol. 112, 2016, pp. 118-128.\n(4) Ismail, Gaber A., et al. An Approach Using Support Vector Machines to Predict Hospital Readmission.\" Journal of Medical Systems, vol. 44, no. 9, 2020, pp. 1-10.\n(5) Xu, Fei, Lihong Li, and Zhihua Zhou. SVM Kernels for Data Mining: A Comparative Study.\" Proceedings of the 2010 SIAM International Conference on Data Mining (SDM), 2010, 585-596.\n(6) Zhou, Xingyu, et al. Using Support Vector Machines for Deep Mining of Electronic Medical Records in Order to Predict Prognosis of Severe, Acute Myocardial Infarction. Frontiers in Cardiovascular Medicine, vol. 10, 2023, p.918.\n(7) Vieira, S.M., Mendonça, L. F., Farinha, G. J., & Sousa, J. M. C. (2013). Modified binary PSO for feature selection using SVM applied to mortality prediction of septic patients. Applied Soft Computing, 13(8), 3494–3504. https://doi.org/10.1016/j.asoc.2013.03.021\n(8) Yang, Zou, H., Wang, M., Zhang, Q., Li, S., & Liang, H. (2023). Mortality prediction among ICU inpatients based on MIMIC-III database results from the conditional medical generative adversarial network. Heliyon, 9(2), e13200–e13200. https://doi.org/10.1016/j.heliyon.2023.e13200\nIntroduction\nSupport Vector Machines (SVM) are a great way to mine data in Electronic Medical Records (EMR). You can use them to find patterns in the data that might be hard to find with regular statistical methods. SVMs can also be used to make models that can use new data to make accurate predictions. It is important to keep in mind, though, that SVMs can be hard to train, especially on big datasets. SVMs can also be responsive to how the SVM kernel and hyperparameters are chosen. Once the SVM model has been trained, it can be used to guess what will happen with new data. For example, a model could be used to figure out how likely it is that a patient will get a certain illness or what will happen to a patient who already has that disease. Before you can use SVMs for data mining in EMRs, you need to prepare the data since the noise and outliers should be taken out of the data. It is also important to feature engineer the data, which will help make new features that may be more useful for the SVM model.\nSVMs can be used to get useful information from the data and to make models that can improve the care of patients. Here are some more reasons why using SVMs for data mining in EMRs is helpful in the clinical setting.  SVMs can determine a model to predict which patients might survive a severe illness in the hospital. This is important for data mining in EMRs, where the data is often complicated since SVMs can handle noise and errors well. This is important for data mining in EMRs because the data may have errors or missing data. Also, models that are easy to understand can be made with SVMs which is important to medical providers so they can explain it to patients and their family.  This is important for data mining in EMRs because it would be helpful to know how the models work, so we can have evidence to support the results. Overall, SVMs are very helpful tools for mining data in EMRs since you get useful information from the data to make models that can improve the care of patients. This can assist in predicting those patients at risk for mortality or death in the Intensive Care Unit (ICU) which are the sickest of the patients."
  },
  {
    "objectID": "Journal/brad.html#methods",
    "href": "Journal/brad.html#methods",
    "title": "SVM application in Data Mining in EMR",
    "section": "Methods",
    "text": "Methods"
  },
  {
    "objectID": "Journal/brad.html#analysis-and-results",
    "href": "Journal/brad.html#analysis-and-results",
    "title": "SVM application in Data Mining in EMR",
    "section": "Analysis and Results",
    "text": "Analysis and Results\n\nData and Visualisation\nA study was conducted to determine how…\n\n\nCode\n# loading packages \nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(ggthemes)\nlibrary(ggrepel)\nlibrary(dslabs)\n\n\n\n\nCode\n# Load Data\nkable(head(murders))\n\n\n\n\n\nstate\nabb\nregion\npopulation\ntotal\n\n\n\n\nAlabama\nAL\nSouth\n4779736\n135\n\n\nAlaska\nAK\nWest\n710231\n19\n\n\nArizona\nAZ\nWest\n6392017\n232\n\n\nArkansas\nAR\nSouth\n2915918\n93\n\n\nCalifornia\nCA\nWest\n37253956\n1257\n\n\nColorado\nCO\nWest\n5029196\n65\n\n\n\n\n\nCode\nggplot1 = murders %&gt;% ggplot(mapping = aes(x=population/10^6, y=total)) \n\n  ggplot1 + geom_point(aes(col=region), size = 4) +\n  geom_text_repel(aes(label=abb)) +\n  scale_x_log10() +\n  scale_y_log10() +\n  geom_smooth(formula = \"y~x\", method=lm,se = F)+\n  xlab(\"Populations in millions (log10 scale)\") + \n  ylab(\"Total number of murders (log10 scale)\") +\n  ggtitle(\"US Gun Murders in 2010\") +\n  scale_color_discrete(name = \"Region\")+\n      theme_bw()\n\n\n\n\n\n\n\nStatistical Modeling\n\n\nConclusion"
  },
  {
    "objectID": "Journal/brad.html#references",
    "href": "Journal/brad.html#references",
    "title": "SVM application in Data Mining in EMR",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "Journal/josh.html",
    "href": "Journal/josh.html",
    "title": "Josh’s Journal Entries",
    "section": "",
    "text": "In Machine learning in medicine: a practical introduction the authors provide a introduction to machine learning in the medical field and a survey of 3 supervised learning methodologies. The begin by explaining how machine learning is related to traditional statistical inference but noted that a major difference is that statistical inference aims to “reach conclusions about a population…” (Sidey-Gibbons, 2) while machine learning aims to predict a specific out come. The authors go on to state that the use of ML in the medical field is relatively easy to explain because many features or parameters that are input can be reasoned about when the prediction is made. An example the authors used were “body mass index and diabetes risk” as the linkage between the two are relatively well known and understood. The author’s then go on to explain the difference between Auditable Algorithms that are easily understood and black box algorithms which are complex and can be hard to reason about. Support Vector Machines can be a member of the later group but not always.\nThe authors then leverage a Generalized Linear model, Support Vector Machine, and Artificial Neural Network to predict whether or not a given breast tissue sample is cancerous. I will skip over the ANN and GLM as our group is not directly focused on them. However with the Support Vector Machine implementation they authors did note that the overall goal is to build a hyperplane that separates two categories the best. Some datasets do not easily separate so it is possible to rearrange the date by using a kernel trick or kernel function to increase the amount of linear separation between observations.\nFinally the authors compared the outcomes of their three algorithms and found that the best one (in terms of accuracy) for the data set they had was the support vector machine. The way they determined this was to build a ROC Curve to find the number of true true predictions and true false predictions\nUWF Access Url\n\n\n\nIn Dibiki et al’s paper on Support vector machines he discussed what SVM’s are and what that the underlying statistical methods are. The paper overall was heavily math based and at times over my head. However it did have information about how and why support vector machines are built. Predominately the author notes that reseacher Vapnik constructed SVM’s based off of Structural Risk Minimaization(SRM) as opposed to Empirical Risk minimization and that SRM proved to be better at creating more generalizable models.\nThe author goes on to explain that the hyperplane is a the maximal margin between data points in a data set. This is called the “Optimal Separating Hyperplane” The authors then went through the math of how to solve for the problems and examples of how to chose kernel functions to ensure that a hyperplane can be found.\nThe examples the author used was were the classification if image data to determine classification of land cover (water, forest, roads, etc) Another example was comparing the performance of an Artificial Neural Network to Support Vector machines to predict stream flow data based on daily rainfall and evaporation based on 3 different locations. The general finding was that SVM and ANN’s can both be readily leveraged to build similar models and predictions\nUWF Access Url"
  },
  {
    "objectID": "Journal/josh.html#machine-learning-in-medicine-a-practical-introduction.-gibbons2019",
    "href": "Journal/josh.html#machine-learning-in-medicine-a-practical-introduction.-gibbons2019",
    "title": "Josh’s Journal Entries",
    "section": "",
    "text": "In Machine learning in medicine: a practical introduction the authors provide a introduction to machine learning in the medical field and a survey of 3 supervised learning methodologies. The begin by explaining how machine learning is related to traditional statistical inference but noted that a major difference is that statistical inference aims to “reach conclusions about a population…” (Sidey-Gibbons, 2) while machine learning aims to predict a specific out come. The authors go on to state that the use of ML in the medical field is relatively easy to explain because many features or parameters that are input can be reasoned about when the prediction is made. An example the authors used were “body mass index and diabetes risk” as the linkage between the two are relatively well known and understood. The author’s then go on to explain the difference between Auditable Algorithms that are easily understood and black box algorithms which are complex and can be hard to reason about. Support Vector Machines can be a member of the later group but not always.\nThe authors then leverage a Generalized Linear model, Support Vector Machine, and Artificial Neural Network to predict whether or not a given breast tissue sample is cancerous. I will skip over the ANN and GLM as our group is not directly focused on them. However with the Support Vector Machine implementation they authors did note that the overall goal is to build a hyperplane that separates two categories the best. Some datasets do not easily separate so it is possible to rearrange the date by using a kernel trick or kernel function to increase the amount of linear separation between observations.\nFinally the authors compared the outcomes of their three algorithms and found that the best one (in terms of accuracy) for the data set they had was the support vector machine. The way they determined this was to build a ROC Curve to find the number of true true predictions and true false predictions\nUWF Access Url"
  },
  {
    "objectID": "Journal/josh.html#model-induction-with-support-vector-machines-introductions-and-applications.dibike2001",
    "href": "Journal/josh.html#model-induction-with-support-vector-machines-introductions-and-applications.dibike2001",
    "title": "Josh’s Journal Entries",
    "section": "",
    "text": "In Dibiki et al’s paper on Support vector machines he discussed what SVM’s are and what that the underlying statistical methods are. The paper overall was heavily math based and at times over my head. However it did have information about how and why support vector machines are built. Predominately the author notes that reseacher Vapnik constructed SVM’s based off of Structural Risk Minimaization(SRM) as opposed to Empirical Risk minimization and that SRM proved to be better at creating more generalizable models.\nThe author goes on to explain that the hyperplane is a the maximal margin between data points in a data set. This is called the “Optimal Separating Hyperplane” The authors then went through the math of how to solve for the problems and examples of how to chose kernel functions to ensure that a hyperplane can be found.\nThe examples the author used was were the classification if image data to determine classification of land cover (water, forest, roads, etc) Another example was comparing the performance of an Artificial Neural Network to Support Vector machines to predict stream flow data based on daily rainfall and evaporation based on 3 different locations. The general finding was that SVM and ANN’s can both be readily leveraged to build similar models and predictions\nUWF Access Url"
  },
  {
    "objectID": "Journal/josh.html#data-mining-concepts-and-techniques-han2012",
    "href": "Journal/josh.html#data-mining-concepts-and-techniques-han2012",
    "title": "Josh’s Journal Entries",
    "section": "Data Mining: Concepts and Techniques (Han and Pei 2012)",
    "text": "Data Mining: Concepts and Techniques (Han and Pei 2012)\nThis review of the text book contains more general information about support vector machines and various applications. It defines that the maximal marginal hyperplane is the single line that can be drawn between two “clusters” of data.This MMH (maximal marginal hyperplane) is defined as a line that can be drawn where the distances between two clusters of data is the largest. It also explains that while we can think of it as a line, the MMH is an actual plane that can support more than 2 dimensions. Additionally the vectors where the hyperplane touch are called the support vectors as the effectively define the sides of the hyper plane.\nIn general the book explains that Support vector machines work very well with linear data sets, their use of kernel functions allow them to operate on non linear data. Kernel functions according to the book can be thought of as mathematic tricks that transform/map data from one dimension to a higher dimensions that is linearly separable."
  },
  {
    "objectID": "Journal/josh.html#support-vector-machines-and-kernel-methods-the-new-generation-of-learning-machines-cristianini2002",
    "href": "Journal/josh.html#support-vector-machines-and-kernel-methods-the-new-generation-of-learning-machines-cristianini2002",
    "title": "Josh’s Journal Entries",
    "section": "Support vector machines and kernel methods: the new generation of learning machines (Cristianini and Scholkopf Fall 2002)",
    "text": "Support vector machines and kernel methods: the new generation of learning machines (Cristianini and Scholkopf Fall 2002)\nIn the article, the author briefly discusses the history of machine learning and its evolution from working predominately on linearly separable datasets to the advancements made with handling non linear data in the 1980s. The author then goes on to discuss the work and presentations of Vapnik et al in 1992. This allowed those wanting to do machine learning data on non linear data in a “principled yet efficient manner”.  (Cristianini and Scholkopf)\none of the other key points that the other makes is that the higher the dimensionality of the problems space, the harder it is to create predictions based on it.\nThe other new and interesting points pointed by the authors where that SVM’s hold records (at the time the article was written) for ability to read handwritten digits and other tasks.This leads to it being very well suited for hand writing detection. Other areas that the models are good according to the author are “text categorization, handwritten digit recognition, and gene expression data classification” (Cristianini and Scholkopf)\nUWF Access Url"
  },
  {
    "objectID": "Journal/josh.html#fast-training-of-support-vector-machines-for-survival-analysis-polsterl2015",
    "href": "Journal/josh.html#fast-training-of-support-vector-machines-for-survival-analysis-polsterl2015",
    "title": "Josh’s Journal Entries",
    "section": "Fast Training of Support Vector Machines for Survival Analysis (Pölsterl, Navab, and Katouzian 2015)",
    "text": "Fast Training of Support Vector Machines for Survival Analysis (Pölsterl, Navab, and Katouzian 2015)\nIn Fast Training of Support Vector Machines for Survival Analysis the author explains that they wish to look at 3 different methods of training a support vector machine for survival analysis: ranking, regression, and a combination of ranking and regressions to determine how well they predict survivability. The author also introduces the concept of censored data. This is a term i hadn’t heard of before but makes sense when explained and in the context of survivability prediction. As explained by the author, data is uncensored if a significant event occurs during the time period in which the study or model is used for. Meanwhile censored data is data in which the event did not occur during the study or observation period, however it may have occurred after the study completes. When thinking about patient survivability this makes sense. For example if we want to study whether or not a patient dies during a hospital stay we probably only want to predict that for a fixed time period (the hospital stay) as we all know every patient will eventually die…perhaps even in a (different) hospital stay!\nThe author then goes on to show how ranking methods such as Cox proportional Hazards and others fair when given certain sized data sets and then comparing that with regression based model. The author summarizes at the end that using ordered statistic trees (which their algorithm uses) is a sufficiently accurate and fast model for predicting patient survivability."
  },
  {
    "objectID": "Journal/josh.html#mortality-prediction-based-on-imbalanced-high-dimensional-icu-big-data-liu2018",
    "href": "Journal/josh.html#mortality-prediction-based-on-imbalanced-high-dimensional-icu-big-data-liu2018",
    "title": "Josh’s Journal Entries",
    "section": "Mortality prediction based on imbalanced high-dimensional ICU big Data (Liu June 2018)",
    "text": "Mortality prediction based on imbalanced high-dimensional ICU big Data (Liu June 2018)\nMortality prediction based on imbalanced high-dimensional ICU big data takes a look at predicting mortality based on a large number of data dimensions with various amounts of data missing. Over all this paper appears to follow an approach that would be good for our project using the MIMIC data set.\nMost of the article goes beyond the scope of Support Vector Machines but delves into principal component analysis to determine what to use to build the support vector machines.The author leverages Cost Sensitive Principal Component Analysis to preprocess the data to deal with missing data and feature extraction. Once this preprocessing step has completed, the authors build a support vector machine to predict mortality. The also build a number of other support vector machines using Chaos particle swarm optimization for parameter optimization and derivatives of CPSO to determine the best model based on the ROC AUC value. In the end the found the SVM using data that had been processed with their modified Cost Sensitive Principal Component Analysis and SPSO\nThrough their findings the authors also opine about the large amount of data and the necessity of determining which are the key features to from which to build a model such as a SVM. They state that the overall number of data points will continue to increase as sensors and technology are continually introduced and improved upon in medical settings and that while the data is great and represents a virtual gold mine, it is important to ensure that data is clean and useful for prediction and not just noisy data for algorithms to churn through"
  },
  {
    "objectID": "Journal/josh.html#artificial-intelligence-in-the-intensive-care-unit-greco2020",
    "href": "Journal/josh.html#artificial-intelligence-in-the-intensive-care-unit-greco2020",
    "title": "Josh’s Journal Entries",
    "section": "Artificial Intelligence in the Intensive Care Unit (Greco, Caruso, and Cecconi 2020)",
    "text": "Artificial Intelligence in the Intensive Care Unit (Greco, Caruso, and Cecconi 2020)\nThe authors of Artificial Intelligence in the Intensive Care Unit describe the ways that medicine can benefit by the usage of machine learning and compares various methods for machine learning. The author goes in depth about why Intensive Care Units are a great place for the introduction of big data practices and machine learning in hospital settings. After introducing the methods of machine learning the paper then discusses the limits of machine learning, examples of machine learning in critical care and the future of big data and machine learning in medicine.\nLive Access URL"
  },
  {
    "objectID": "Journal/josh.html#predictive-modelling-of-survival-and-length-of-stay-in-critically-ill-patients-using-sequential-organ-failure-scores-houthooft2015",
    "href": "Journal/josh.html#predictive-modelling-of-survival-and-length-of-stay-in-critically-ill-patients-using-sequential-organ-failure-scores-houthooft2015",
    "title": "Josh’s Journal Entries",
    "section": "Predictive modelling of survival and length of stay in critically ill patients using sequential organ failure scores (Houthooft et al. 2015)",
    "text": "Predictive modelling of survival and length of stay in critically ill patients using sequential organ failure scores (Houthooft et al. 2015)\nThe paper “Predictive modelling of survival and length of stay in critically ill patients using sequential organ failure scores” the authors talk about ways to use machine learning to model the length of stay as a predictor of patient mortality. The author talks about choosing the data sets and selecting certain features for modeling based on data from th first five days of a patients stay to predict both the patients mortality and their length of stay. The results of the SVM the author built were compared to regression results to model the length of stay and then compared with mortality for patients with lengthy ICE stays. The author goes on to conclude that the models can be helpful to support physicians allocate ICU resources and make decisions during a patients time in ICU."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Predicting Survival of Intensive Care Unit Patients with Support Vector Machines",
    "section": "",
    "text": "Every day sensors and systems are capturing a virtual flood of data points and feeding those values into powerful artificial intelligence and machine learning systems to derive classifications and predict a myriad of outcomes. These systems help us do a broad spectrum of things from fraud detection to interactions with smart home systems. Given the number of data points that are present in the medical field, it is of no surprise that machine learning is increasingly being leveraged to elevate patient care.\nFor as long as most of us remember, our interactions with physicians have included the gathering of data points to help them detect illness and track progression of disease. Common data points are age, weight, height, temperature, blood pressure, list of any current symptoms and etc. Physicians then use their education and years of practice to provide diagnoses and help us live happy and healthy lives. But what if this was process could be supported with machine learning, and brought into a more critical care setting?\nWe can. Thanks to machine learning we can use data from the countless sensors and measurements taken by medical staff in Intensive Care Units (ICU) to predict the survivability of patients under care. This data can then help teams organize around certain cases to help ensure the best allotment of resources and highest attention to the most dire of cases. A method we will use in this report is through the construction of Support Vector Machines or SVM’s.\nSVM’s are a machine learning methodology that uses supervised learning based on historic cases to help train models that can then be used on other cases. Models created by Support Vector Machines are used to create clusters of 2 distinct groups of data based on the creation of a maximally-marginal hyperplane.(Han and Pei 2012). A maximally-marginal hyperplane can be explained as a line that can be drawn between two clusters that separates their members with the greatest distance between members of each cluster that are their nearest.\nWhile we did not find many cases of using support vector machines for ICU patient survival, the use of Support Vector Machines in medicine is not a novel approach. In “Using Support Vector Machines for Diabetes Mellitus Classification from Electronic Medical Records” by Adeoye the author leveraged electronic medical records to help classify individuals with and without diabetes. Meanwhile, Zhou et al where able to use Support Vector Machines to predict the prognosis of severe, acute myocardial infarction with 92% accuracy from electronic medical records(Zhou 2023)\nWhile Support Vector Machines can be a great utility used to cluster and predict outcomes, their usage in Medicine is not without problems. One problem noted by Liu et al is that the sheer number of data points available can make it hard to find features (data points of importance) for use in model construction.(Liu June 2018) In fact Liu goes as far as describing the use of Principal Component Analysis to chose which features to include in model construction. Additionally, support vector machines work best when the data can be mapped linearly, however unlike other methodologies this is not a strict requirement. Should data not be easily linearly separable the use of a kernel function or kernel trick allows data to be mapped from one space to another for optimal construction of the maximally marginal hyperplane (Han and Pei 2012) (Mohan et al. 2020)"
  },
  {
    "objectID": "index.html#statistical-modeling",
    "href": "index.html#statistical-modeling",
    "title": "Predicting Survival of Intensive Care Unit Patients with Support Vector Machines",
    "section": "Statistical Modeling",
    "text": "Statistical Modeling\nGiven that Support Vector Machines operate on both linear and non-linear data, we must look at how a Support Vector Machine manipulates non-linear data to a linear space to perform classification. This operation id done via a kernel function or “kernel trick”. The general formula for a kernel function is as follows.\n\\[\nK(X_i, X_j) = \\Phi(X_i)\\Phi(X_j)  \n\\]\nWhere \\(X_i, X_j\\) is a tuple.\nOnce the data linear (and therfore linearly separable), we can define our maximally marginal hyperplane. A general formual for the hyperplane is as follows \\[\nW \\times X + b = 0\n\\]\nThis formual has 2 components of import. The first is a \\(W\\), a weight vector and \\(b\\) a scalar bias\nSince \\(W\\) is a simple weighting vector it would be in the form of\n\\[\nW = \\{w_1, w_2, \\dots, w_n \\}\n\\]\nThe tuples that lie the closest to the margins of the maximal marginal hyperplane are the actual support vectors.\nUsing the formulas above, if our support vectors where at \\(y_i = 1\\) and \\(y_i = -1\\) our hyperplane margines would be defined as\n\\[\nH_1: W_0 + W_{1}X_{1} + W_{2}X_{2} + \\dots + W_{n}X_{n} \\ge 1\n\\]\nand\n\\[\nH_2: W_0 + W_{1}X_{1} + W_{2}X_{2} + \\dots + W_{n}X_{n} \\le -1\n\\]"
  },
  {
    "objectID": "index.html#model",
    "href": "index.html#model",
    "title": "Predicting Survival of Intensive Care Unit Patients with Support Vector Machines",
    "section": "Model",
    "text": "Model\nA two-step approach was used to estimate tuning parameters and evaluate operational characteristics of the SVM models using the best combination of tuning parameters: in the first step, for each combination of parameters, 10 training datasets were fitted and each of them was validated using 10 different validation datasets. The combination of parameters with largest accuracy was used to measure the performance of the models in the second step. In the second step, new 10 datasets were simulated for estimation of models given the best combination of tuning parameters found in the first step and for each of those, 10 testing datasets were simulated to compare the performance of the SVM models based on the following metrics: accuracy (proportion of correctly classified), area under the ROC curve (AUC-ROC), sensitivity, specificity and F1 score. Therefore, 100 datasets have been tested and used to compute the mean and the standard deviation of the metrics used as a summary performance of each method.\nWe applied this to our dataset from the e1071 package available in the R software repository. Parameters were tuned and the accuracy, AUC-ROC, sensitivity, specificity and F1 score was estimated through a 10-fold nested-cross validation repeating the process in 10 resampled datasets.\n\n\nCode\n# a random number based on keyboard bashing the number row to ensure that our random data set is repeatable \n# while we are reporting on it\nset.seed(01923904)\n\n# Create a subset of the entire dataset to just include the rows we have determined are of interest\n# convert the gender field to an `is_male` flag\nmodel_data &lt;- mimic_data %&gt;%\n    select(\n        age,\n        gender,\n        hospital_expire_flag,\n        heartrate_mean,\n        sysbp_mean,\n        resprate_mean,\n        tempc_mean,\n        wbc_mean,\n        platelet_min,\n        creatinine_max,\n        lactate_mean\n    ) %&gt;%\n    mutate(is_male = case_when(gender == \"M\" ~ 1, TRUE ~ 0))\n\n# drop all observations with an NA for any value\nmodel_data &lt;- na.omit(model_data)\n\n# ensure that hospital expire flag is a factor\nmodel_data$hospital_expire_flag &lt;- as.factor(model_data$hospital_expire_flag)\n\n# assign an id for each element in the row\nmodel_data$id &lt;- 1:nrow(model_data)\n\n# Divide our dataset into a training and test set with 80% of data going to training and 20% to test\ntrain &lt;- model_data %&gt;% dplyr::sample_frac(0.8)\ntest  &lt;- dplyr::anti_join(model_data, train, by = 'id')\n\n#Tune the model based on a list of costs ranging from 0.001 -&gt; 100 by 10x steps \nmodelTuning.out &lt;- tune(svm, \n  hospital_expire_flag ~ ., data = train, \n  kernel = \"linear\", \n  ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)), \n  scale = TRUE)\n\n# take the best model from the tuning and use it\nmodel &lt;- modelTuning.out$best.model\nsummary(model)\n\n\n\nCall:\nbest.tune(METHOD = svm, train.x = hospital_expire_flag ~ ., data = train, \n    ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)), kernel = \"linear\", \n    scale = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  linear \n       cost:  0.1 \n\nNumber of Support Vectors:  1156\n\n ( 599 557 )\n\n\nNumber of Classes:  2 \n\nLevels: \n 0 1\n\n\nCode\n# run predictions based on our model against the test set\npredictions &lt;- predict(model, test)\n\n# Construct a confusion matrix and print it out\nconfusionMatrix(table(actual=test$hospital_expire_flag, prediction=predictions), positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n      prediction\nactual   0   1\n     0 727   0\n     1 161   0\n                                          \n               Accuracy : 0.8187          \n                 95% CI : (0.7917, 0.8435)\n    No Information Rate : 1               \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity :     NA          \n            Specificity : 0.8187          \n         Pos Pred Value :     NA          \n         Neg Pred Value :     NA          \n             Prevalence : 0.0000          \n         Detection Rate : 0.0000          \n   Detection Prevalence : 0.1813          \n      Balanced Accuracy :     NA          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nCode\n# Challenger Model \n\n# a random number based on keyboard bashing the number row to ensure that our random data set is repeatable \n# while we are reporting on it\nset.seed(123)\n\n# Create a smaller subset than the original subset to test against\n# convert the gender field to an `is_male` flag\nmodel_data &lt;- mimic_data %&gt;%\n  select(\n    age,\n    gender,\n    hospital_expire_flag,\n    heartrate_mean,\n    sysbp_mean,\n    resprate_mean,\n    tempc_mean,\n    platelet_min,\n  ) %&gt;%\n  mutate(is_male = case_when(gender == \"M\" ~ 1, TRUE ~ 0))\n\n# drop all observations with an NA for any value\nmodel_data &lt;- na.omit(model_data)\n\n# ensure that hospital expire flag is a factor\nmodel_data$hospital_expire_flag &lt;- as.factor(model_data$hospital_expire_flag)\n\n# assign an id for each element in the row\nmodel_data$id &lt;- 1:nrow(model_data)\n\n# Divide our dataset into a training and test set with 80% of data going to training and 20% to test\ntrain &lt;- model_data %&gt;% dplyr::sample_frac(0.8)\ntest  &lt;- dplyr::anti_join(model_data, train, by = 'id')\n\n#Tune the model based on a list of costs ranging from 0.001 -&gt; 100 by 10x steps \nmodelTuning.out &lt;- tune(svm, \n                        hospital_expire_flag ~ ., data = train, \n                        kernel = \"linear\", \n                        ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)), \n                        scale = TRUE)\n\n# take the best model from the tuning and use it\nmodel &lt;- modelTuning.out$best.model\nsummary(model)\n\n\n\nCall:\nbest.tune(METHOD = svm, train.x = hospital_expire_flag ~ ., data = train, \n    ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)), kernel = \"linear\", \n    scale = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  linear \n       cost:  0.001 \n\nNumber of Support Vectors:  1146\n\n ( 575 571 )\n\n\nNumber of Classes:  2 \n\nLevels: \n 0 1\n\n\nCode\n# run predictions based on our model against the test set\npredictions &lt;- predict(model, test)\n\n# Construct a confusion matrix and print it out\nconfusionMatrix(table(actual=test$hospital_expire_flag, prediction=predictions), positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n      prediction\nactual   0   1\n     0 741   0\n     1 147   0\n                                          \n               Accuracy : 0.8345          \n                 95% CI : (0.8084, 0.8583)\n    No Information Rate : 1               \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity :     NA          \n            Specificity : 0.8345          \n         Pos Pred Value :     NA          \n         Neg Pred Value :     NA          \n             Prevalence : 0.0000          \n         Detection Rate : 0.0000          \n   Detection Prevalence : 0.1655          \n      Balanced Accuracy :     NA          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "index.html#data-and-vizualisation",
    "href": "index.html#data-and-vizualisation",
    "title": "Predicting Survival of Intensive Care Unit Patients with Support Vector Machines",
    "section": "Data and Vizualisation",
    "text": "Data and Vizualisation\n\n\nCode\nlibrary(gtsummary)\n\nmimic_data %&gt;%\nmutate(\n  gender = case_when(gender == \"M\" ~ \"male\",\n                     gender == \"F\" ~ \"female\",\n                     TRUE ~ gender),\n  survived = case_when(hospital_expire_flag == 1 ~ \"Died\",\n                     hospital_expire_flag == 0 ~ \"Survived\")\n) %&gt;%  \nselect(\n  age, \n  gender, \n  survived, \n  heartrate_mean,\n  sysbp_mean,\n  resprate_mean,\n  tempc_mean,\n  wbc_mean,\n  platelet_min,\n  creatinine_max,\n  lactate_mean\n) %&gt;%\n  tbl_summary(\n    type = list(age ~ 'continuous2',\n    gender ~ 'categorical', resprate_mean ~ 'continuous2',\n    heartrate_mean ~ 'continuous2',\n    tempc_mean ~ 'continuous2',\n    wbc_mean ~ 'continuous2',\n    platelet_min ~ 'continuous2',\n    creatinine_max ~ 'continuous2',\n    lactate_mean ~ 'continuous2',\n    sysbp_mean ~ 'continuous2'),\n    label = list(\n      age ~ \"Patient Age\",\n      gender ~ \"Patient Sex\",\n      heartrate_mean ~ \"Heart Rate\",\n      sysbp_mean ~ \"Systolic Blood Pressure\",\n      resprate_mean ~ \"Respiration Rate\",\n      tempc_mean ~ \"Body Temperature (c)\",\n      wbc_mean ~ \"White Blood Cell Count\",\n      platelet_min ~\"Platelet Count\",\n      creatinine_max ~\"Creatinine Level\",\n      lactate_mean ~\"Lactate Level\"\n       ),\n      statistic = all_continuous() ~ c(\"{median}({p25}, {p75})\", \"{min}, {max}\"),\n      by = survived \n  ) %&gt;%\n  add_overall(last = TRUE) %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%   as_gt() %&gt;%\n  gt_theme_dark() %&gt;%\n  tab_options(\n    table.background.color = \"#d8e4ea\",\n    column_labels.background.color=\"#5092c2\",\n    table.align = \"left\"\n  )\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Died, N = 7411\n      Survived, N = 3,8181\n      Overall, N = 4,5591\n    \n  \n  \n    Patient Age\n\n\n\n        Median(IQR)\n73(60, 83)\n65(53, 78)\n67(54, 80)\n        Range\n17, 91\n17, 91\n17, 91\n    Patient Sex\n\n\n\n        female\n339 (46%)\n1,639 (43%)\n1,978 (43%)\n        male\n402 (54%)\n2,179 (57%)\n2,581 (57%)\n    Heart Rate\n\n\n\n        Median(IQR)\n92(77, 106)\n87(76, 99)\n88(76, 100)\n        Range\n47, 155\n36, 139\n36, 155\n    Systolic Blood Pressure\n\n\n\n        Median(IQR)\n108(100, 120)\n115(106, 126)\n114(105, 126)\n        Range\n70, 175\n76, 195\n70, 195\n        Unknown\n2\n6\n8\n    Respiration Rate\n\n\n\n        Median(IQR)\n21.5(18.4, 24.9)\n18.9(16.6, 21.9)\n19.3(16.8, 22.4)\n        Range\n11.3, 40.6\n9.5, 40.4\n9.5, 40.6\n        Unknown\n0\n1\n1\n    Body Temperature (c)\n\n\n\n        Median(IQR)\n36.62(36.11, 37.19)\n36.87(36.47, 37.32)\n36.82(36.41, 37.31)\n        Range\n31.60, 39.71\n32.61, 40.10\n31.60, 40.10\n        Unknown\n20\n83\n103\n    White Blood Cell Count\n\n\n\n        Median(IQR)\n13(9, 18)\n12(8, 15)\n12(8, 16)\n        Range\n0, 404\n0, 207\n0, 404\n    Platelet Count\n\n\n\n        Median(IQR)\n166(95, 253)\n180(126, 245)\n178(122, 246)\n        Range\n8, 951\n5, 1,297\n5, 1,297\n        Unknown\n1\n5\n6\n    Creatinine Level\n\n\n\n        Median(IQR)\n1.60(1.00, 2.60)\n1.10(0.80, 1.70)\n1.20(0.90, 1.90)\n        Range\n0.20, 14.40\n0.10, 27.80\n0.10, 27.80\n        Unknown\n1\n1\n2\n    Lactate Level\n\n\n\n        Median(IQR)\n2.55(1.70, 4.50)\n1.80(1.30, 2.55)\n1.90(1.35, 2.75)\n        Range\n0.40, 20.85\n0.30, 16.80\n0.30, 20.85\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\nPatient Demographics\n\nPatient Age\n\n\nCode\nggplot(mimic_data, aes(x=age))+ \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nPatient Sex\n\n\nCode\nmimic_data &lt;- mimic_data %&gt;% mutate(\n  gender = case_when(gender == \"M\" ~ \"male\",\n                     gender == \"F\" ~ \"female\",\n                     TRUE ~ gender)\n)\n\npatient_sex_viz &lt;- mimic_data %&gt;%\n  group_by(gender) %&gt;%\n  summarise(N = n()) %&gt;%\n  mutate(\n    gender = as.factor(gender),\n    pos = cumsum(N) - N/2,\n    label = paste(N,  \" \", gender, \"\\npatients\\n(\", 100*round(N/sum(N), 2), \"%)\", sep=\"\")\n  )\n\nggplot(patient_sex_viz, aes(x = \"\", y = N, fill = gender)) +\n  geom_bar(stat = \"identity\", width=1, color=\"white\", position = \"stack\") +  \n  coord_polar(theta = \"y\", direction = -1, clip = \"off\") +\n  theme_economist(base_family=\"ITC Officina Sans\") + \n  theme(\n    legend.position=\"none\",\n    line=element_blank(),\n    axis.title.x=element_blank(),\n    axis.text.x=element_blank(), #remove x axis labels\n    axis.ticks.x=element_blank(), #remove x axis ticks\n    axis.title.y=element_blank(),\n    axis.text.y=element_blank(),  #remove y axis labels\n    axis.ticks.y=element_blank()  #remove y axis ticks\n  ) + \n  geom_text(aes(y = pos, label = label), color = \"white\", size=6) +\n  scale_fill_economist(labels=NULL)\n\n\n\n\n\n\n\n\n\n\n\nPatient Survival\n\n\nCode\nmimic_data &lt;- mimic_data %&gt;% mutate(\n  survived = case_when(hospital_expire_flag == 1 ~ \"Died\",\n                     hospital_expire_flag == 0 ~ \"Survived\")\n)\n\nggplot(mimic_data, aes(x = survived, fill=survived)) +\n  geom_bar(color=\"white\") +  \n  theme_economist(base_family=\"ITC Officina Sans\") +\n  scale_fill_economist(labels=NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nVital Signs\n\nHeart rate\n\n\nCode\nggplot(mimic_data, aes(x=heartrate_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nBlood pressure: Median systolic blood pressure 134 mmHg (Q1–Q3: 116–154 mmHg); median diastolic blood pressure 78 mmHg (Q1–Q3: 66–90 mmHg)\n\n\nCode\nggplot(mimic_data, aes(x=sysbp_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nRespiratory rate\n\n\nCode\nggplot(mimic_data, aes(x=resprate_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nTemperature\n\n\nCode\nggplot(mimic_data, aes(x=tempc_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nOxygen saturation: Median 96% (Q1–Q3: 93–99%)\n\n\nCode\nggplot(mimic_data, aes(x=spo2_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\n\nLaboratory Values\n\nWhite blood cell count: Median 10.5 × 10^9 cells/L (Q1–Q3: 7.5–14.5 × 10^9 cells/L)\n\n\nCode\nggplot(mimic_data, aes(x=wbc_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nNeutrophil count: Median 7.5 × 10^9 cells/L (Q1–Q3: 5.4–11.2 × 10^9 cells/L)\nNOT FOUND IN DATA\n\n\nLymphocyte count: Median 1.7 × 10^9 cells/L (Q1–Q3: 1.0–2.5 × 10^9 cells/L)\nNOT FOUND IN DATA\n\n\nPlatelet count: Median 178 × 10^9 cells/L (Q1–Q3: 125–240 × 10^9 cells/L)\n\n\nCode\nggplot(mimic_data, aes(x=platelet_min)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nCreatinine: Median 1.0 mg/dL (Q1–Q3: 0.8–1.3 mg/dL)\n\n\nCode\nggplot(mimic_data, aes(x=creatinine_max)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")\n\n\n\n\n\n\n\nBilirubin: Median 0.8 mg/dL (Q1–Q3: 0.5–1.2 mg/dL)\nNOT FOUND IN DATA #### Lactate dehydrogenase: Median 250 U/L (Q1–Q3: 190–330 U/L)\n\n\nCode\nggplot(mimic_data, aes(x=lactate_mean)) + \n  geom_histogram( color=\"#e9ecef\", fill=\"#188bc2\", alpha=0.9, position = 'identity') +\n  theme_economist(base_family=\"ITC Officina Sans\")"
  }
]