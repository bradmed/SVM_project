Cristianini, N., & Scholkopf, B. (2002, Fall). Support vector machines and kernel methods: the new generation of learning machines. (Articles). _AI Magazine_, _23_(3), 31+. https://link-gale-com.ezproxy.lib.uwf.edu/apps/doc/A92806024/EAIM?u=pens49866&sid=bookmark-EAIM&xid=d7a7aa96


In the article, the author briefly discusses the history of machine learning and its evolution from working predominately on linearly separable datasets to the advancements made with handling non linear data in the 1980s. The author then goes on to discuss the work and presentations of Vapnik et al in 1992. This allowed those wanting to do machine learning data on non linear data in a "principled yet efficient manner". Â (Cristianini and Scholkopf)

one of the other key points that the other makes is that the higher the dimensionality of the problems space, the harder it is to create predictions based on it.

The other new and interesting points pointed by the authors where that SVM's hold records (at the time the article was written) for ability to read handwritten digits and other tasks.This leads to it being very well suited for hand writing detection. Other areas that the models are good according to the author are "text categorization, handwritten digit recognition, and gene expression data classification"  (Cristianini and Scholkopf)

