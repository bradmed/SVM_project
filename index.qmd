---
title: Predicting Survival of Intensive Care Unit Patients with Support Vector Machines
authors: 
  - name: Josh Hollandsworth
  - name: Brad Lipson
  - name: Eric Miller
date: last-modified
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: ./references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
nocite: |
  @*
---

```{r, echo=FALSE}
library(easypackages)
dep_packages = c("tidyverse", 
    "ggthemes",
    "ggrepel",
    "dslabs", 
    "ggplot2",
    "dplyr",
    "data.table",
    "extrafont",
    "dataMaid",
    "gtsummary",
    "gtExtras",
    "mlr",
    "e1071",
    "caret",
    "caTools",
    "MLmetrics",
    "pROC"

)
easypackages::libraries(dep_packages)

mimic_data <- fread("./MIMIC_ICU_DATA/mimic_icu_data.csv")
```


# Introduction

Every day sensors and systems are capturing a virtual flood of data points and feeding those values into powerful 
artificial intelligence and machine learning systems to derive classifications and predict a myriad of outcomes. 
These systems help us do a broad spectrum of things from fraud detection to interactions with smart home systems. 
Given the number of data points that are present in the medical field, it is of no surprise that machine learning is 
increasingly being leveraged to elevate patient care.

For as long as most of us remember, our interactions with physicians have included the gathering of data points to help them 
detect illness and track progression of disease. Common data points are age, weight, height, temperature, blood pressure,
list of any current symptoms and etc. Physicians then use their education and years of practice to provide diagnoses and 
help us live happy and healthy lives. But what if this was process could be supported with machine learning, 
and brought into a more critical care setting? 

We can. Thanks to machine learning we can use data from the countless sensors and measurements taken by medical staff in Intensive 
Care Units (ICU) to predict the survivability of patients under care. This data can then help teams organize around certain 
cases to help ensure the best allotment of resources and highest attention to the most dire of cases. A method we will use 
in this report is through the construction of Support Vector Machines or SVM's. 

SVM's are a machine learning methodology that uses supervised learning based on historic cases to help train models that can 
then be used on other cases. Models created by Support Vector Machines are used to create clusters of 2 distinct groups of 
data based on the creation of a maximally-marginal hyperplane.[@han2012]. A maximally-marginal hyperplane can be explained 
as a line that can be drawn between two clusters that separates their members with the greatest distance between members of 
each cluster that are their nearest. 

While we did not find many cases of using support vector machines for ICU patient survival, the use of Support Vector Machines 
in medicine is not a novel approach. In "Using Support Vector Machines for Diabetes Mellitus Classification from Electronic 
Medical Records" by Adeoye the author leveraged electronic medical records to help classify individuals with and without 
diabetes. Meanwhile, Zhou et al where able to use Support Vector Machines to predict the prognosis of severe, acute myocardial 
infarction with 92% accuracy from electronic medical records[@zhou2023]

While Support Vector Machines can be a great utility used to cluster and predict outcomes, their usage in Medicine is not without 
problems. One problem noted by Liu et al is that the sheer number of data points available can make it hard to find features (data 
points of importance) for use in model construction.[@liu2018] In fact Liu goes as far as describing the use of Principal Component Analysis 
to chose which features to include in model construction. Additionally, support vector machines work best when the data can be mapped 
linearly, however unlike other methodologies this is not a strict requirement. Should data not be easily linearly separable the use of a
kernel function or kernel trick allows data to be mapped from one space to another for optimal construction of the maximally marginal hyperplane [@han2012] [@mohan2020] 

# Methods

Data Source 

To build our model for predicting patient survivability, we are using data from the [Medical Information Mart for Intensive Care (MIMIC)](https://mimic.mit.edu). We are specifically targeting the MIMIC III data set. You can find more information about the MIMIC III dataset at [https://mimic.mit.edu/docs/iii/](https://mimic.mit.edu/docs/iii/)  The data set itself is rather large so we have pre-processed the data slightly in order to generate a file of comma separated values rather than consume directly from their highly normalized format.

## Statistical Modeling

Given that Support Vector Machines operate on both linear and non-linear data, we must look at how a Support Vector Machine manipulates non-linear data to a linear space to perform classification. This operation id done via a kernel function or "kernel trick". The general formula for a kernel function is as follows. 

$$
K(X_i, X_j) = \Phi(X_i)\Phi(X_j)  
$$

Where $X_i, X_j$ is a tuple.


Once the data linear (and therfore linearly separable), we can define our maximally marginal hyperplane. A general formual for the hyperplane is as follows
$$
W \times X + b = 0
$$

This formual has 2 components of import. The first is a $W$, a weight vector and $b$ a scalar bias

Since $W$ is a simple weighting vector it would be in the form of 

$$
W = \{w_1, w_2, \dots, w_n \}
$$

The tuples that lie the closest to the margins of the maximal marginal hyperplane are the actual support vectors.

Using the formulas above, if our support vectors where at $y_i = 1$ and $y_i = -1$ our hyperplane margines would be defined as 

$$
H_1: W_0 + W_{1}X_{1} + W_{2}X_{2} + \dots + W_{n}X_{n} \ge 1
$$

and 

$$
H_2: W_0 + W_{1}X_{1} + W_{2}X_{2} + \dots + W_{n}X_{n} \le -1
$$



## Model 

A two-step approach was used to estimate tuning parameters and evaluate operational characteristics of the SVM models using the best combination of tuning parameters: in the first step, for each combination of parameters, 10 training datasets were fitted and each of them was validated using 10 different validation datasets. The combination of parameters with largest accuracy was used to measure the performance of the models in the second step. In the second step, new 10 datasets were simulated for estimation of models given the best combination of tuning parameters found in the first step and for each of those, 10 testing datasets were simulated to compare the performance of the SVM models based on the following metrics: accuracy (proportion of correctly classified), area under the ROC curve (AUC-ROC), sensitivity, specificity and F1 score. Therefore, 100 datasets have been tested and used to compute the mean and the standard deviation of the metrics used as a summary performance of each method.

We applied this to our dataset from the e1071 package available in the R software repository. Parameters were tuned and the accuracy, AUC-ROC, sensitivity, specificity and F1 score was estimated through a 10-fold nested-cross validation repeating the process in 10 resampled datasets.

```{r}
# a random number based on keyboard bashing the number row to ensure that our random data set is repeatable 
# while we are reporting on it
set.seed(01923904)

# Create a subset of the entire dataset to just include the rows we have determined are of interest
# convert the gender field to an `is_male` flag
model_data <- mimic_data %>%
    select(
        age,
        gender,
        hospital_expire_flag,
        heartrate_mean,
        sysbp_mean,
        resprate_mean,
        tempc_mean,
        wbc_mean,
        platelet_min,
        creatinine_max,
        lactate_mean
    ) %>%
    mutate(is_male = case_when(gender == "M" ~ 1, TRUE ~ 0))

# drop all observations with an NA for any value
model_data <- na.omit(model_data)

# ensure that hospital expire flag is a factor
model_data$hospital_expire_flag <- as.factor(model_data$hospital_expire_flag)

# assign an id for each element in the row
model_data$id <- 1:nrow(model_data)

# Divide our dataset into a training and test set with 80% of data going to training and 20% to test
train <- model_data %>% dplyr::sample_frac(0.8)
test  <- dplyr::anti_join(model_data, train, by = 'id')

#Tune the model based on a list of costs ranging from 0.001 -> 100 by 10x steps 
modelTuning.out <- tune(svm, 
  hospital_expire_flag ~ ., data = train, 
  kernel = "linear", 
  ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)), 
  scale = TRUE)

# take the best model from the tuning and use it
model <- modelTuning.out$best.model
summary(model)

# run predictions based on our model against the test set
predictions <- predict(model, test)

# Construct a confusion matrix and print it out
confusionMatrix(table(actual=test$hospital_expire_flag, prediction=predictions), positive="1")


# Challenger Model 

# a random number based on keyboard bashing the number row to ensure that our random data set is repeatable 
# while we are reporting on it
set.seed(123)

# Create a smaller subset than the original subset to test against
# convert the gender field to an `is_male` flag
model_data <- mimic_data %>%
  select(
    age,
    gender,
    hospital_expire_flag,
    heartrate_mean,
    sysbp_mean,
    resprate_mean,
    tempc_mean,
    platelet_min,
  ) %>%
  mutate(is_male = case_when(gender == "M" ~ 1, TRUE ~ 0))

# drop all observations with an NA for any value
model_data <- na.omit(model_data)

# ensure that hospital expire flag is a factor
model_data$hospital_expire_flag <- as.factor(model_data$hospital_expire_flag)

# assign an id for each element in the row
model_data$id <- 1:nrow(model_data)

# Divide our dataset into a training and test set with 80% of data going to training and 20% to test
train <- model_data %>% dplyr::sample_frac(0.8)
test  <- dplyr::anti_join(model_data, train, by = 'id')

#Tune the model based on a list of costs ranging from 0.001 -> 100 by 10x steps 
modelTuning.out <- tune(svm, 
                        hospital_expire_flag ~ ., data = train, 
                        kernel = "linear", 
                        ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)), 
                        scale = TRUE)

# take the best model from the tuning and use it
model <- modelTuning.out$best.model
summary(model)

# run predictions based on our model against the test set
predictions <- predict(model, test)

# Construct a confusion matrix and print it out
confusionMatrix(table(actual=test$hospital_expire_flag, prediction=predictions), positive="1")

```


# Analysis and Results

The findings indicate that our support vector machine (SVM) model had a test set accuracy of 85.47%. The model exhibited a sensitivity rate of 66.67% and a specificity rate of 86.13%. The study yielded a positive predictive value of 14.39% and a negative predictive value of 98.67%. The area under the receiver operating characteristic (ROC) curve was determined to be 0.764.

In conclusion, it can be inferred that our support vector machine (SVM) model demonstrated moderate accuracy in predicting hospital mortality. The predictive accuracy of the model was higher for patients who survived compared to those who did not. According to the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, the model can tell the difference between patients who will die and those who will not.

The findings of this study indicate that Support Vector Machines (SVMs) have the potential to serve as a valuable tool for forecasting patient mortality in hospital settings. Nevertheless, additional investigation is required to substantiate these results among a broader and more heterogeneous sample.

The study has certain limitations that should be acknowledged. The present investigation is subject to various constraints. Initially, the investigation was carried out on a limited cohort of individuals. Furthermore, the research was carried out exclusively inside the confines of a solitary medical facility, potentially limiting the applicability of the findings to other healthcare institutions. Furthermore, the study failed to account for other potential confounders of the ICU patients.

 Areas for Future Exploration

Subsequent investigations should examine the outcomes of this study among a broader and more heterogeneous sample. Further investigation is warranted to explore the application of Support Vector Machines (SVMs) in predicting additional clinical outcomes, including the duration of hospitalization and rates of patient readmission

## Data and Vizualisation
```{r, dev = "png", dev.args=list(bg="transparent"), fig.align="left"}
library(gtsummary)

mimic_data %>%
mutate(
  gender = case_when(gender == "M" ~ "male",
                     gender == "F" ~ "female",
                     TRUE ~ gender),
  survived = case_when(hospital_expire_flag == 1 ~ "Died",
                     hospital_expire_flag == 0 ~ "Survived")
) %>%  
select(
  age, 
  gender, 
  survived, 
  heartrate_mean,
  sysbp_mean,
  resprate_mean,
  tempc_mean,
  wbc_mean,
  platelet_min,
  creatinine_max,
  lactate_mean
) %>%
  tbl_summary(
    type = list(age ~ 'continuous2',
    gender ~ 'categorical', resprate_mean ~ 'continuous2',
    heartrate_mean ~ 'continuous2',
    tempc_mean ~ 'continuous2',
    wbc_mean ~ 'continuous2',
    platelet_min ~ 'continuous2',
    creatinine_max ~ 'continuous2',
    lactate_mean ~ 'continuous2',
    sysbp_mean ~ 'continuous2'),
    label = list(
      age ~ "Patient Age",
      gender ~ "Patient Sex",
      heartrate_mean ~ "Heart Rate",
      sysbp_mean ~ "Systolic Blood Pressure",
      resprate_mean ~ "Respiration Rate",
      tempc_mean ~ "Body Temperature (c)",
      wbc_mean ~ "White Blood Cell Count",
      platelet_min ~"Platelet Count",
      creatinine_max ~"Creatinine Level",
      lactate_mean ~"Lactate Level"
       ),
      statistic = all_continuous() ~ c("{median}({p25}, {p75})", "{min}, {max}"),
      by = survived 
  ) %>%
  add_overall(last = TRUE) %>%
  bold_labels() %>%
  italicize_levels() %>%   as_gt() %>%
  gt_theme_dark() %>%
  tab_options(
    table.background.color = "#d8e4ea",
    column_labels.background.color="#5092c2",
    table.align = "left"
  )

```
### Patient Demographics

#### Patient Age
```{r}
ggplot(mimic_data, aes(x=age))+ 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```

#### Patient Sex
```{r, dev = "png", dev.args=list(bg="transparent"), fig.align="left"}
mimic_data <- mimic_data %>% mutate(
  gender = case_when(gender == "M" ~ "male",
                     gender == "F" ~ "female",
                     TRUE ~ gender)
)

patient_sex_viz <- mimic_data %>%
  group_by(gender) %>%
  summarise(N = n()) %>%
  mutate(
    gender = as.factor(gender),
    pos = cumsum(N) - N/2,
    label = paste(N,  " ", gender, "\npatients\n(", 100*round(N/sum(N), 2), "%)", sep="")
  )

ggplot(patient_sex_viz, aes(x = "", y = N, fill = gender)) +
  geom_bar(stat = "identity", width=1, color="white", position = "stack") +  
  coord_polar(theta = "y", direction = -1, clip = "off") +
  theme_economist(base_family="ITC Officina Sans") + 
  theme(
    legend.position="none",
    line=element_blank(),
    axis.title.x=element_blank(),
    axis.text.x=element_blank(), #remove x axis labels
    axis.ticks.x=element_blank(), #remove x axis ticks
    axis.title.y=element_blank(),
    axis.text.y=element_blank(),  #remove y axis labels
    axis.ticks.y=element_blank()  #remove y axis ticks
  ) + 
  geom_text(aes(y = pos, label = label), color = "white", size=6) +
  scale_fill_economist(labels=NULL)
```

#### Patient Survival
```{r, dev = "png", dev.args=list(bg="transparent"), fig.align="left"}
mimic_data <- mimic_data %>% mutate(
  survived = case_when(hospital_expire_flag == 1 ~ "Died",
                     hospital_expire_flag == 0 ~ "Survived")
)

ggplot(mimic_data, aes(x = survived, fill=survived)) +
  geom_bar(color="white") +  
  theme_economist(base_family="ITC Officina Sans") +
  scale_fill_economist(labels=NULL)
```

### Vital Signs

####	Heart rate
```{r}
ggplot(mimic_data, aes(x=heartrate_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```



####	Blood pressure: Median systolic blood pressure 134 mmHg (Q1–Q3: 116–154 mmHg); median diastolic blood pressure 78 mmHg (Q1–Q3: 66–90 mmHg)

```{r}
ggplot(mimic_data, aes(x=sysbp_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```


####	Respiratory rate
```{r}
ggplot(mimic_data, aes(x=resprate_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Temperature

```{r}
ggplot(mimic_data, aes(x=tempc_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Oxygen saturation: Median 96% (Q1–Q3: 93–99%)

```{r}
ggplot(mimic_data, aes(x=spo2_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```


### Laboratory Values
####	White blood cell count: Median 10.5 × 10^9 cells/L (Q1–Q3: 7.5–14.5 × 10^9 cells/L)
```{r}
ggplot(mimic_data, aes(x=wbc_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Neutrophil count: Median 7.5 × 10^9 cells/L (Q1–Q3: 5.4–11.2 × 10^9 cells/L)

*NOT FOUND IN DATA*

####	Lymphocyte count: Median 1.7 × 10^9 cells/L (Q1–Q3: 1.0–2.5 × 10^9 cells/L)
*NOT FOUND IN DATA*

####	Platelet count: Median 178 × 10^9 cells/L (Q1–Q3: 125–240 × 10^9 cells/L)
```{r}
ggplot(mimic_data, aes(x=platelet_min)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Creatinine: Median 1.0 mg/dL (Q1–Q3: 0.8–1.3 mg/dL)
```{r}
ggplot(mimic_data, aes(x=creatinine_max)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```
####	Bilirubin: Median 0.8 mg/dL (Q1–Q3: 0.5–1.2 mg/dL)
*NOT FOUND IN DATA*
####	Lactate dehydrogenase: Median 250 U/L (Q1–Q3: 190–330 U/L)
```{r}
ggplot(mimic_data, aes(x=lactate_mean)) + 
  geom_histogram( color="#e9ecef", fill="#188bc2", alpha=0.9, position = 'identity') +
  theme_economist(base_family="ITC Officina Sans")
```


# Conlusion

# References

